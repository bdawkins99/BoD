\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{urbanowicz17,urbanowicz17b,robnik2003}
\citation{venkataraman2010,hay2017,sundermann2014,vergun2013}
\citation{stir,urbanowicz17,urbanowicz17b}
\citation{arabnejad2018}
\citation{stir}
\citation{stir}
\@writefile{toc}{\contentsline {section}{\numberline {1}Limit distribution for $L_q$ on null data}{2}{section.1}\protected@file@percent }
\newlabel{sec:notation_and_CLT}{{1}{2}{Limit distribution for \texorpdfstring {$L_q$}{} on null data}{section.1}{}}
\newlabel{eq:D}{{1}{2}{Limit distribution for \texorpdfstring {$L_q$}{} on null data}{equation.1.1}{}}
\citation{allStats}
\newlabel{eq:diff}{{2}{3}{Limit distribution for \texorpdfstring {$L_q$}{} on null data}{equation.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Asymptotic normality of pairwise distances}{3}{subsection.1.1}\protected@file@percent }
\newlabel{eq:diffDistr}{{3}{3}{Asymptotic normality of pairwise distances}{equation.1.3}{}}
\newlabel{eq:DqAsympt}{{4}{3}{Asymptotic normality of pairwise distances}{equation.1.4}{}}
\newlabel{eq:DqDeltaMethod}{{5}{4}{Asymptotic normality of pairwise distances}{equation.1.5}{}}
\newlabel{eq:DqImprovedExplained}{{6}{4}{Asymptotic normality of pairwise distances}{equation.1.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Convergence to Gaussian for Manhattan and Euclidean distances for simulated standard uniform data with $m=100$ instances and $p=10, 100,$ and $10000$ attributes. Convergence to Gaussian occurs rapidly with increasing $p$, and Gaussian is a good approximation for $p$ as low as $10$ attributes. The number of attributes in bioinformatics data is typically much larger, at least on the order of $10^3$. The Euclidean metric has stronger convergence to normal than Manhattan. P values from Shapiro-Wilk test, where the null hypothesis is a Gaussian distribution.\relax }}{5}{figure.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:central_limit_convergence}{{1}{5}{Convergence to Gaussian for Manhattan and Euclidean distances for simulated standard uniform data with $m=100$ instances and $p=10, 100,$ and $10000$ attributes. Convergence to Gaussian occurs rapidly with increasing $p$, and Gaussian is a good approximation for $p$ as low as $10$ attributes. The number of attributes in bioinformatics data is typically much larger, at least on the order of $10^3$. The Euclidean metric has stronger convergence to normal than Manhattan. P values from Shapiro-Wilk test, where the null hypothesis is a Gaussian distribution.\relax }{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Convergence to Gaussian for Manhattan and Euclidean distances for simulated standard normal data with $m=100$ instances and $p=10, 100,$ and $10000$ attributes. Convergence to Gaussian occurs rapidly with increasing $p$, and Gaussian is a good approximation for $p$ as low as $10$ attributes. The number of attributes in bioinformatics data is typically much larger, at least on the order of $10^3$. The Euclidean metric has stronger convergence to normal than Manhattan. P values from Shapiro-Wilk test, where the null hypothesis is a Gaussian distribution.\relax }}{6}{figure.2}\protected@file@percent }
\newlabel{fig:central_limit_convergence_normal}{{2}{6}{Convergence to Gaussian for Manhattan and Euclidean distances for simulated standard normal data with $m=100$ instances and $p=10, 100,$ and $10000$ attributes. Convergence to Gaussian occurs rapidly with increasing $p$, and Gaussian is a good approximation for $p$ as low as $10$ attributes. The number of attributes in bioinformatics data is typically much larger, at least on the order of $10^3$. The Euclidean metric has stronger convergence to normal than Manhattan. P values from Shapiro-Wilk test, where the null hypothesis is a Gaussian distribution.\relax }{figure.2}{}}
\citation{freund2004}
\@writefile{toc}{\contentsline {section}{\numberline {2}$L_q$ metric moments for continuous data distributions}{7}{section.2}\protected@file@percent }
\newlabel{sec:moment_derivations}{{2}{7}{\texorpdfstring {$L_q$}{} metric moments for continuous data distributions}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Distribution of $|\text  {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{7}{subsection.2.1}\protected@file@percent }
\newlabel{thm:freund}{{2.1}{7}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{theorem.2.1}{}}
\newlabel{eq:E(1)}{{11}{8}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.11}{}}
\newlabel{eq:E(2)}{{12}{8}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.12}{}}
\newlabel{eq:DqCDF}{{13}{8}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.13}{}}
\newlabel{eq:DqPDF}{{14}{8}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.14}{}}
\newlabel{eq:1DDqMean}{{15}{9}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.15}{}}
\newlabel{eq:1DDqVar}{{16}{9}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.16}{}}
\newlabel{eq:DqDistr}{{17}{9}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.17}{}}
\newlabel{eq:DDistr}{{18}{9}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Standard normal data}{9}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{eq:normalXmarg}{{19}{9}{Standard normal data}{equation.2.19}{}}
\newlabel{eq:normalXMinusZmarg}{{20}{9}{Standard normal data}{equation.2.20}{}}
\newlabel{eq:normalXPlusZmarg}{{21}{9}{Standard normal data}{equation.2.21}{}}
\newlabel{eq:normalPDF}{{22}{9}{Standard normal data}{equation.2.22}{}}
\newlabel{eq:1DnormalDqMean}{{27}{10}{Standard normal data}{equation.2.27}{}}
\newlabel{eq:1DnormalDqVar}{{28}{10}{Standard normal data}{equation.2.28}{}}
\newlabel{eq:normalDqMean}{{29}{10}{Standard normal data}{equation.2.29}{}}
\newlabel{eq:normalVar}{{30}{10}{Standard normal data}{equation.2.30}{}}
\newlabel{eq:normalDistr}{{31}{10}{Standard normal data}{equation.2.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Standard uniform data}{10}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{eq:uniformXmarg}{{32}{10}{Standard uniform data}{equation.2.32}{}}
\newlabel{eq:uniformXMinusZmarg}{{33}{10}{Standard uniform data}{equation.2.33}{}}
\newlabel{eq:uniformXPlusZmarg}{{34}{11}{Standard uniform data}{equation.2.34}{}}
\newlabel{eq:uniformDqPDF}{{35}{11}{Standard uniform data}{equation.2.35}{}}
\newlabel{eq:uniformDqMGF}{{36}{11}{Standard uniform data}{equation.2.36}{}}
\newlabel{eq:1DuniformDqMean}{{37}{11}{Standard uniform data}{equation.2.37}{}}
\newlabel{eq:1DuniformDqVar}{{38}{11}{Standard uniform data}{equation.2.38}{}}
\newlabel{eq:uniformDqMean}{{39}{11}{Standard uniform data}{equation.2.39}{}}
\newlabel{eq:uniformDqVar}{{40}{12}{Standard uniform data}{equation.2.40}{}}
\newlabel{eq:uniformDistr}{{41}{12}{Standard uniform data}{equation.2.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Manhattan ($L_1$)}{12}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Standard normal data}{12}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{eq:normalManMean}{{42}{12}{Standard normal data}{equation.2.42}{}}
\newlabel{eq:normalManVar}{{43}{13}{Standard normal data}{equation.2.43}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Standard uniform data}{13}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{eq:uniformManMean}{{44}{13}{Standard uniform data}{equation.2.44}{}}
\newlabel{eq:uniformManVar}{{45}{13}{Standard uniform data}{equation.2.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Euclidean ($L_2$)}{13}{subsection.2.3}\protected@file@percent }
\citation{brazma2000,wang2018}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Standard normal data}{14}{subsubsection.2.3.1}\protected@file@percent }
\newlabel{eq:normalEucMean}{{46}{14}{Standard normal data}{equation.2.46}{}}
\newlabel{eq:normalEucVar}{{47}{14}{Standard normal data}{equation.2.47}{}}
\newlabel{eq:normalEucMeanImproved}{{48}{14}{Standard normal data}{equation.2.48}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Standard uniform data}{14}{subsubsection.2.3.2}\protected@file@percent }
\citation{urbanowicz17,robnik2003,urbanowiczReliefReview2018}
\citation{robnik2003,urbanowiczReliefReview2018,urbanowicz17}
\newlabel{eq:uniformEucMean}{{49}{15}{Standard uniform data}{equation.2.49}{}}
\newlabel{eq:uniformEucVar}{{50}{15}{Standard uniform data}{equation.2.50}{}}
\newlabel{eq:uniformEucMeanImproved}{{51}{15}{Standard uniform data}{equation.2.51}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Distribution of max-min normalized $L_q$ metric}{15}{subsection.2.4}\protected@file@percent }
\newlabel{sec:extremes}{{2.4}{15}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{subsection.2.4}{}}
\newlabel{eq:normDiff}{{52}{15}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.52}{}}
\newlabel{thm:EVT}{{2.2}{16}{Fisher-Tippett-Gnedenko}{theorem.2.2}{}}
\newlabel{eq:exact_max}{{53}{16}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.53}{}}
\newlabel{eq:exact_max_distr_fn}{{54}{16}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.54}{}}
\newlabel{eq:exact_max_dens_fn}{{55}{16}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.55}{}}
\newlabel{eq:exact_min}{{56}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.56}{}}
\newlabel{eq:exact_min_distr_fn}{{57}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.57}{}}
\newlabel{eq:exact_min_dens_fn}{{58}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.58}{}}
\newlabel{eq:mu_max}{{59}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.59}{}}
\newlabel{eq:mu2_max}{{60}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.60}{}}
\newlabel{eq:sig_max}{{61}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.61}{}}
\newlabel{eq:mu_min}{{62}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.62}{}}
\citation{gumbel1947}
\newlabel{eq:mu2_min}{{63}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.63}{}}
\newlabel{eq:sig_min}{{64}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.64}{}}
\newlabel{eq:exp_rng}{{65}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.65}{}}
\newlabel{eq:exp_rng_symm}{{66}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.66}{}}
\newlabel{eq:var_rng}{{67}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.67}{}}
\newlabel{eq:var_rng_symm}{{68}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.68}{}}
\newlabel{eq:max-min_D_mean}{{69}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.69}{}}
\newlabel{eq:max-min_D_var}{{70}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.70}{}}
\newlabel{eq:max-min-DDistr-general}{{71}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.71}{}}
\newlabel{eq:max-min_D_mean_symm}{{72}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.72}{}}
\newlabel{eq:max-min_D_var_symm}{{73}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.73}{}}
\citation{chatterjee2014}
\newlabel{eq:max-min_DDistr}{{74}{20}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.74}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Standard normal data}{20}{subsubsection.2.4.1}\protected@file@percent }
\newlabel{eq:log_expand}{{75}{20}{Standard normal data}{equation.2.75}{}}
\newlabel{eq:mills}{{76}{20}{Standard normal data}{equation.2.76}{}}
\newlabel{eq:approx_log_expand}{{77}{20}{Standard normal data}{equation.2.77}{}}
\citation{cramer1999}
\citation{gumbel1947}
\newlabel{eq:prob_normal_max}{{78}{21}{Standard normal data}{equation.2.78}{}}
\newlabel{eq:mu_max_normal}{{79}{21}{Standard normal data}{equation.2.79}{}}
\newlabel{eq:med_max_normal}{{80}{21}{Standard normal data}{equation.2.80}{}}
\newlabel{eq:var_max_normal}{{81}{21}{Standard normal data}{equation.2.81}{}}
\newlabel{eq:var_max_normal_improved}{{82}{21}{Standard normal data}{equation.2.82}{}}
\newlabel{eq:mu_rng_normal}{{83}{21}{Standard normal data}{equation.2.83}{}}
\newlabel{eq:var_rng_normal}{{84}{22}{Standard normal data}{equation.2.84}{}}
\newlabel{eq:mu_rng_normal_improved}{{85}{22}{Standard normal data}{equation.2.85}{}}
\newlabel{eq:max-min_DDistr_normal}{{86}{22}{Standard normal data}{equation.2.86}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Standard uniform data}{22}{subsubsection.2.4.2}\protected@file@percent }
\newlabel{eq:uniform_max_distr}{{87}{22}{Standard uniform data}{equation.2.87}{}}
\newlabel{eq:uniform_min_distr}{{88}{22}{Standard uniform data}{equation.2.88}{}}
\newlabel{eq:uniform_max_dens}{{89}{22}{Standard uniform data}{equation.2.89}{}}
\newlabel{eq:uniform_min_dens}{{90}{22}{Standard uniform data}{equation.2.90}{}}
\newlabel{eq:mu_max_uniform}{{91}{23}{Standard uniform data}{equation.2.91}{}}
\newlabel{eq:mu_min_uniform}{{92}{23}{Standard uniform data}{equation.2.92}{}}
\newlabel{eq:mu2_rng_uniform}{{93}{23}{Standard uniform data}{equation.2.93}{}}
\newlabel{eq:max-min_DDistr_uniform}{{94}{23}{Standard uniform data}{equation.2.94}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Normalized Manhattan ($q=1$)}{23}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Standard normal data}{24}{subsubsection.2.5.1}\protected@file@percent }
\newlabel{eq:max-min_manhattan_normal_mean}{{95}{24}{Standard normal data}{equation.2.95}{}}
\newlabel{eq:max-min_manhattan_normal_var}{{96}{24}{Standard normal data}{equation.2.96}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Standard uniform data}{24}{subsubsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Normalized Euclidean ($q=2$)}{24}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}Standard normal data}{24}{subsubsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}Standard uniform data}{25}{subsubsection.2.6.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of distance distribution derivations for standard normal and standard uniform data. Asymptotic estimates are given for both standard and max-min normalized q-metrics. These estimates are relevant for all $q \in \mathbb  {N}$ and $p \geq 100$.\relax }}{26}{table.caption.4}\protected@file@percent }
\newlabel{tab:dist_distr_general1}{{1}{26}{Summary of distance distribution derivations for standard normal and standard uniform data. Asymptotic estimates are given for both standard and max-min normalized q-metrics. These estimates are relevant for all $q \in \mathbb {N}$ and $p \geq 100$.\relax }{table.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Asymptotic estimates for means and variances for the standard $L_1$ and $L_2$ distance distributions. Estimates for both standard normal and standard uniform data are given.\relax }}{27}{table.caption.5}\protected@file@percent }
\newlabel{tab:dist_distr_standardL1L2}{{2}{27}{Asymptotic estimates for means and variances for the standard $L_1$ and $L_2$ distance distributions. Estimates for both standard normal and standard uniform data are given.\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Asymptotic estimates for means and variances for the max-min normalized $L_1$ and $L_2$ distance distributions. Estimates for both standard normal and standard uniform data are given.\relax }}{28}{table.caption.6}\protected@file@percent }
\newlabel{tab:dist_distr_normalizedL1L2}{{3}{28}{Asymptotic estimates for means and variances for the max-min normalized $L_1$ and $L_2$ distance distributions. Estimates for both standard normal and standard uniform data are given.\relax }{table.caption.6}{}}
\citation{arabnejad2018}
\@writefile{toc}{\contentsline {section}{\numberline {3}GWAS distance distributions}{29}{section.3}\protected@file@percent }
\newlabel{sec:gwas_distances}{{3}{29}{GWAS distance distributions}{section.3}{}}
\newlabel{eq:gwas_data}{{103}{29}{GWAS distance distributions}{equation.3.103}{}}
\newlabel{eq:diff_GM}{{104}{29}{GWAS distance distributions}{equation.3.104}{}}
\newlabel{eq:diff_AM}{{105}{29}{GWAS distance distributions}{equation.3.105}{}}
\newlabel{eq:diff_TiTv}{{106}{29}{GWAS distance distributions}{equation.3.106}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}GM distance distribution}{30}{subsection.3.1}\protected@file@percent }
\newlabel{eq:mean_diff_GM}{{107}{30}{GM distance distribution}{equation.3.107}{}}
\newlabel{eq:mu_DDistr_GM}{{108}{30}{GM distance distribution}{equation.3.108}{}}
\newlabel{eq:mu2_DDistr_GM}{{109}{30}{GM distance distribution}{equation.3.109}{}}
\newlabel{eq:var_DDistr_GM}{{110}{31}{GM distance distribution}{equation.3.110}{}}
\newlabel{eq:DDistr_GM}{{111}{31}{GM distance distribution}{equation.3.111}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}AM distance distribution}{31}{subsection.3.2}\protected@file@percent }
\newlabel{eq:mean_diff_AM}{{112}{31}{AM distance distribution}{equation.3.112}{}}
\newlabel{eq:mu_DDistr_AM}{{113}{31}{AM distance distribution}{equation.3.113}{}}
\newlabel{eq:mu2_DDistr_AM}{{114}{32}{AM distance distribution}{equation.3.114}{}}
\newlabel{eq:var_DDistr_AM}{{115}{32}{AM distance distribution}{equation.3.115}{}}
\newlabel{eq:DDistr_AM}{{116}{32}{AM distance distribution}{equation.3.116}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}TiTv distance distribution}{32}{subsection.3.3}\protected@file@percent }
\newlabel{sec:TiTv_distances}{{3.3}{32}{TiTv distance distribution}{subsection.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Purines (A and G) and pyrimidines (C and T) are shown. Transitions occur when a mutation involves purine-to-purine or pyrimidine-to-pyrimidine insertion. Transversions occur when a purine-to-pyrimidine or pyrimidine-to-purine insertion happens, which is a more extreme case. There are visibly more possibilities for transversions to occur than there are transitions, but there are about twice as many transitions in real data.\relax }}{33}{figure.3}\protected@file@percent }
\newlabel{fig:TiTv_diagram}{{3}{33}{Purines (A and G) and pyrimidines (C and T) are shown. Transitions occur when a mutation involves purine-to-purine or pyrimidine-to-pyrimidine insertion. Transversions occur when a purine-to-pyrimidine or pyrimidine-to-purine insertion happens, which is a more extreme case. There are visibly more possibilities for transversions to occur than there are transitions, but there are about twice as many transitions in real data.\relax }{figure.3}{}}
\newlabel{eq:TiTv_constraints1}{{117}{33}{TiTv distance distribution}{equation.3.117}{}}
\newlabel{eq:TiTv_constraints2}{{118}{33}{TiTv distance distribution}{equation.3.118}{}}
\newlabel{eq:prob_Tv}{{119}{33}{TiTv distance distribution}{equation.3.119}{}}
\newlabel{eq:prob_Ti}{{120}{33}{TiTv distance distribution}{equation.3.120}{}}
\newlabel{eq:gamma0}{{121}{33}{TiTv distance distribution}{equation.3.121}{}}
\newlabel{eq:gamma2}{{122}{33}{TiTv distance distribution}{equation.3.122}{}}
\newlabel{eq:yvec}{{123}{34}{TiTv distance distribution}{equation.3.123}{}}
\newlabel{eq:prob_TiTv_0}{{124}{34}{TiTv distance distribution}{equation.3.124}{}}
\newlabel{eq:prob_TiTv_0.25}{{125}{34}{TiTv distance distribution}{equation.3.125}{}}
\newlabel{eq:prob_TiTv_0.5}{{126}{34}{TiTv distance distribution}{equation.3.126}{}}
\newlabel{eq:prob_TiTv_0.75}{{127}{34}{TiTv distance distribution}{equation.3.127}{}}
\newlabel{eq:prob_TiTv_1}{{128}{35}{TiTv distance distribution}{equation.3.128}{}}
\newlabel{eq:mu_DDistr_TiTv}{{129}{35}{TiTv distance distribution}{equation.3.129}{}}
\newlabel{eq:mu2_DDistr_TiTv}{{130}{35}{TiTv distance distribution}{equation.3.130}{}}
\newlabel{eq:var_DDistr_TiTv}{{131}{36}{TiTv distance distribution}{equation.3.131}{}}
\newlabel{eq:DDistr_TiTv}{{132}{36}{TiTv distance distribution}{equation.3.132}{}}
\newlabel{eq:avg_maf}{{133}{36}{TiTv distance distribution}{equation.3.133}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Predicted average TiTv distance as a function of average minor allele frequency $\mathaccentV {bar}016{f}_a$ (see Eq.\nobreakspace  {}\ref  {eq:avg_maf}). Success probabilities $f_a$ were drawn from a sliding window interval from 0.01 to 0.9 in increments of about 0.009. With $\eta =0.1$, where $\eta $ is the Ti/Tv ratio given by Eq.\nobreakspace  {}\ref  {eq:TiTv_constraints1}, Tv is ten times more likely than Ti so the distance is large. Increasing to $\eta =1$, Tv and Ti are equally likely so the distance is moderate. In line with real data for $\eta =2$, Tv is half as likely as Ti so the distance is relatively small.\relax }}{37}{figure.4}\protected@file@percent }
\newlabel{fig:TiTv-vs-maf}{{4}{37}{Predicted average TiTv distance as a function of average minor allele frequency $\bar {f}_a$ (see Eq.~\ref {eq:avg_maf}). Success probabilities $f_a$ were drawn from a sliding window interval from 0.01 to 0.9 in increments of about 0.009. With $\eta =0.1$, where $\eta $ is the Ti/Tv ratio given by Eq.~\ref {eq:TiTv_constraints1}, Tv is ten times more likely than Ti so the distance is large. Increasing to $\eta =1$, Tv and Ti are equally likely so the distance is moderate. In line with real data for $\eta =2$, Tv is half as likely as Ti so the distance is relatively small.\relax }{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Density curves and moments of TiTv distance as a function of average MAF $\mathaccentV {bar}016{f}_a$, given by Eq.\nobreakspace  {}\ref  {eq:avg_maf}, and Ti/Tv ratio $\eta $, given by Eq.\nobreakspace  {}\ref  {eq:TiTv_constraints2}. (\textbf  {A}) For fixed $\eta =2$, TiTv distance density is plotted as a function of increasing $\mathaccentV {bar}016{f}_a = 0.055, 0.150, 0.250, \text  { and } 0.350$. TiTv distance increases as $\mathaccentV {bar}016{f}_a$ approaches a maximum of 0.5, which means that there is about the same frequency of minor alleles as primary alleles at locus $a$. (\textbf  {B}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing Ti/Tv ratio $\eta $. Distance decreases as Tv becomes more frequent than Ti. Theoretical standard deviation is slightly larger than simulated, but the means are approximately the same. (\textbf  {C}) For fixed $\mathaccentV {bar}016{f}_a=0.055$, TiTv distance density is plotted as a function of increasing $\eta = 0.5, 1, 1.5, \text  { and } 2$. TiTv distance decreases as $\eta $, the Ti/Tv ratio, increases. For $\eta =\text  {Ti/Tv}=0.5$, there are twice as many transversions as there are transitions. On the other hand, $\eta =\text  {Ti/Tv}=2$ indicates that there are half as many transversions as there are transitions. Since transversions encode a larger magnitude distance than transitions in Eq.\nobreakspace  {}\ref  {eq:diff_TiTv}, this behavior is expected. (\textbf  {D}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing average MAF $\mathaccentV {bar}016{f}_a$. Distance increases as the number of minor alleles increases at each locus $a$. Theoretical and simulated moments are approximately the same.\relax }}{38}{figure.5}\protected@file@percent }
\newlabel{fig:TiTv_ridge}{{5}{38}{Density curves and moments of TiTv distance as a function of average MAF $\bar {f}_a$, given by Eq.~\ref {eq:avg_maf}, and Ti/Tv ratio $\eta $, given by Eq.~\ref {eq:TiTv_constraints2}. (\textbf {A}) For fixed $\eta =2$, TiTv distance density is plotted as a function of increasing $\bar {f}_a = 0.055, 0.150, 0.250, \text { and } 0.350$. TiTv distance increases as $\bar {f}_a$ approaches a maximum of 0.5, which means that there is about the same frequency of minor alleles as primary alleles at locus $a$. (\textbf {B}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing Ti/Tv ratio $\eta $. Distance decreases as Tv becomes more frequent than Ti. Theoretical standard deviation is slightly larger than simulated, but the means are approximately the same. (\textbf {C}) For fixed $\bar {f}_a=0.055$, TiTv distance density is plotted as a function of increasing $\eta = 0.5, 1, 1.5, \text { and } 2$. TiTv distance decreases as $\eta $, the Ti/Tv ratio, increases. For $\eta =\text {Ti/Tv}=0.5$, there are twice as many transversions as there are transitions. On the other hand, $\eta =\text {Ti/Tv}=2$ indicates that there are half as many transversions as there are transitions. Since transversions encode a larger magnitude distance than transitions in Eq.~\ref {eq:diff_TiTv}, this behavior is expected. (\textbf {D}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing average MAF $\bar {f}_a$. Distance increases as the number of minor alleles increases at each locus $a$. Theoretical and simulated moments are approximately the same.\relax }{figure.5}{}}
\citation{lee2013}
\citation{dickie2017}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Summary of distance distribution derivations for GWAS data.\relax }}{39}{table.caption.7}\protected@file@percent }
\newlabel{tab:dist_distr_gwas}{{4}{39}{Summary of distance distribution derivations for GWAS data.\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Time series correlation-based distance distribution}{39}{section.4}\protected@file@percent }
\newlabel{sec:rs-fMRI_distances}{{4}{39}{Time series correlation-based distance distribution}{section.4}{}}
\newlabel{eq:diff_rs-fMRI}{{134}{39}{Time series correlation-based distance distribution}{equation.4.134}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Resting-state fMRI transformed subject correlation matrices. Each column corresponds to an instance (or subject) $I_j$ and each column corresponds to an ROI (or feature). The notation $\mathaccentV {hat}05E{A}^{(j)}_{ka}$ represents the r-to-z transformed correlation between ROIs $a$ and $k \not =a$ for instance $j$.\relax }}{40}{figure.6}\protected@file@percent }
\newlabel{fig:rs-fMRI_matrix}{{6}{40}{Resting-state fMRI transformed subject correlation matrices. Each column corresponds to an instance (or subject) $I_j$ and each column corresponds to an ROI (or feature). The notation $\hat {A}^{(j)}_{ka}$ represents the r-to-z transformed correlation between ROIs $a$ and $k \neq a$ for instance $j$.\relax }{figure.6}{}}
\newlabel{eq:mu_DDistr_rs-fMRI}{{135}{40}{Time series correlation-based distance distribution}{equation.4.135}{}}
\newlabel{eq:var_DDistr_rs-fMRI}{{136}{41}{Time series correlation-based distance distribution}{equation.4.136}{}}
\newlabel{eq:estimate_cov}{{137}{41}{Time series correlation-based distance distribution}{equation.4.137}{}}
\newlabel{eq:estimate_cov_form}{{138}{41}{Time series correlation-based distance distribution}{equation.4.138}{}}
\newlabel{eq:var_DDistr_rs-fMRI2}{{139}{41}{Time series correlation-based distance distribution}{equation.4.139}{}}
\newlabel{eq:DDistr_rs-fMRI}{{140}{41}{Time series correlation-based distance distribution}{equation.4.140}{}}
\newlabel{eq:max-min_diff_rs-fMRI}{{141}{42}{Time series correlation-based distance distribution}{equation.4.141}{}}
\newlabel{eq:mean_max_rs-fMRI}{{142}{42}{Time series correlation-based distance distribution}{equation.4.142}{}}
\newlabel{eq:var_max_rs-fMRI}{{143}{42}{Time series correlation-based distance distribution}{equation.4.143}{}}
\newlabel{eq:max-min_DDistr_normal_rs-fMRI}{{144}{42}{Time series correlation-based distance distribution}{equation.4.144}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Normalized Manhattan ($q=1$) for rs-fMRI}{42}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Summary of distance distribution derivations for rs-fMRI data.\relax }}{43}{table.caption.8}\protected@file@percent }
\newlabel{tab:dist_distr_rs-fMRI}{{5}{43}{Summary of distance distribution derivations for rs-fMRI data.\relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Effects of correlation on distances}{43}{section.5}\protected@file@percent }
\newlabel{sec:correlation}{{5}{43}{Effects of correlation on distances}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Continuous data}{43}{subsection.5.1}\protected@file@percent }
\newlabel{eq:abs_corr}{{147}{44}{Continuous data}{equation.5.147}{}}
\newlabel{eq:cholesky}{{148}{44}{Continuous data}{equation.5.148}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}GWAS data}{44}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Correlation-based data}{44}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Ridgeline plots of uncorrelated vs correlated densities in bioinformatics data. (\textbf  {A}) \relax }}{45}{figure.7}\protected@file@percent }
\newlabel{fig:null_vs_correlated_ridge}{{7}{45}{Ridgeline plots of uncorrelated vs correlated densities in bioinformatics data. (\textbf {A}) \relax }{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{45}{section.6}\protected@file@percent }
\newlabel{sec:discussion}{{6}{45}{Discussion}{section.6}{}}
\bibstyle{unsrt}
\bibdata{BoD}
\bibcite{urbanowicz17}{1}
\bibcite{urbanowicz17b}{2}
\bibcite{robnik2003}{3}
\bibcite{venkataraman2010}{4}
\bibcite{hay2017}{5}
\bibcite{sundermann2014}{6}
\bibcite{vergun2013}{7}
\bibcite{stir}{8}
\bibcite{arabnejad2018}{9}
\bibcite{allStats}{10}
\bibcite{freund2004}{11}
\bibcite{brazma2000}{12}
\bibcite{wang2018}{13}
\bibcite{urbanowiczReliefReview2018}{14}
\bibcite{gumbel1947}{15}
\bibcite{chatterjee2014}{16}
\bibcite{cramer1999}{17}
\bibcite{lee2013}{18}
\bibcite{dickie2017}{19}
\newlabel{LastPage}{{}{48}{}{page.48}{}}
\xdef\lastpage@lastpage{48}
\xdef\lastpage@lastpageHy{48}
