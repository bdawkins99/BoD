\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plos2015}
\citation{urbanowicz17,urbanowicz17b,robnik2003}
\citation{npdr2}
\citation{stir,mckinney13}
\providecommand \oddpage@label [2]{}
\citation{robnik2003}
\citation{arabnejad2018}
\citation{arabnejad2018}
\citation{venkataraman2010,hay2017,sundermann2014,vergun2013}
\citation{le17}
\citation{gotts2012}
\citation{npdr2}
\citation{mckinney13}
\@writefile{toc}{\contentsline {section}{\numberline {1}Limit distribution for $L_q$ on null data}{3}{section.1}\protected@file@percent }
\newlabel{sec:notation_and_CLT}{{1}{3}{Limit distribution for \texorpdfstring {$L_q$}{} on null data}{section.1}{}}
\newlabel{eq:D}{{1}{3}{Limit distribution for \texorpdfstring {$L_q$}{} on null data}{equation.1.1}{}}
\newlabel{eq:diff}{{2}{3}{Limit distribution for \texorpdfstring {$L_q$}{} on null data}{equation.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Nearest-neighbor projected-distance regression}{3}{subsection.1.1}\protected@file@percent }
\citation{liu2019}
\citation{t1000}
\citation{power2011}
\citation{shen2013}
\newlabel{eq:npdr-logit}{{3}{4}{Nearest-neighbor projected-distance regression}{equation.1.3}{}}
\newlabel{eq:pheno-diff}{{4}{4}{Nearest-neighbor projected-distance regression}{equation.1.4}{}}
\citation{allStats}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Asymptotic normality of pairwise distances}{5}{subsection.1.2}\protected@file@percent }
\newlabel{eq:diffDistr}{{6}{5}{Asymptotic normality of pairwise distances}{equation.1.6}{}}
\newlabel{eq:DqAsympt}{{7}{5}{Asymptotic normality of pairwise distances}{equation.1.7}{}}
\newlabel{eq:DqDeltaMethod}{{8}{5}{Asymptotic normality of pairwise distances}{equation.1.8}{}}
\newlabel{eq:DqImprovedExplained}{{9}{6}{Asymptotic normality of pairwise distances}{equation.1.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces {\bf  Convergence to Gaussian for Manhattan and Euclidean distances for simulated standard uniform data with $m=100$ instances and $p=10, 100,$ and $10000$ attributes.} Convergence to Gaussian occurs rapidly with increasing $p$, and Gaussian is a good approximation for $p$ as low as $10$ attributes. The number of attributes in bioinformatics data is typically much larger, at least on the order of $10^3$. The Euclidean metric has stronger convergence to normal than Manhattan. P values from Shapiro-Wilk test, where the null hypothesis is a Gaussian distribution.\relax }}{6}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:central_limit_convergence}{{1}{6}{{\bf Convergence to Gaussian for Manhattan and Euclidean distances for simulated standard uniform data with $m=100$ instances and $p=10, 100,$ and $10000$ attributes.} Convergence to Gaussian occurs rapidly with increasing $p$, and Gaussian is a good approximation for $p$ as low as $10$ attributes. The number of attributes in bioinformatics data is typically much larger, at least on the order of $10^3$. The Euclidean metric has stronger convergence to normal than Manhattan. P values from Shapiro-Wilk test, where the null hypothesis is a Gaussian distribution.\relax }{figure.caption.3}{}}
\citation{freund2004}
\@writefile{toc}{\contentsline {section}{\numberline {2}$L_q$ metric moments for continuous data distributions}{7}{section.2}\protected@file@percent }
\newlabel{sec:moment_derivations}{{2}{7}{\texorpdfstring {$L_q$}{} metric moments for continuous data distributions}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Distribution of $|\text  {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{7}{subsection.2.1}\protected@file@percent }
\newlabel{thm:freund}{{2.1}{7}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{theorem.2.1}{}}
\newlabel{eq:E(1)}{{14}{8}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.14}{}}
\newlabel{eq:E(2)}{{15}{8}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.15}{}}
\newlabel{eq:DqCDF}{{16}{8}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.16}{}}
\newlabel{eq:DqPDF}{{17}{8}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.17}{}}
\newlabel{eq:1DDqMean}{{18}{9}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.18}{}}
\newlabel{eq:1DDqVar}{{19}{9}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.19}{}}
\newlabel{eq:DqDistr}{{20}{9}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.20}{}}
\newlabel{eq:DDistr}{{21}{9}{Distribution of \texorpdfstring {$|\text {d}_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Standard normal data}{9}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{eq:normalXmarg}{{22}{9}{Standard normal data}{equation.2.22}{}}
\newlabel{eq:normalXMinusZmarg}{{23}{9}{Standard normal data}{equation.2.23}{}}
\newlabel{eq:normalXPlusZmarg}{{24}{9}{Standard normal data}{equation.2.24}{}}
\newlabel{eq:normalPDF}{{25}{9}{Standard normal data}{equation.2.25}{}}
\newlabel{eq:1DnormalDqMean}{{26}{10}{Standard normal data}{equation.2.26}{}}
\newlabel{eq:1DnormalDqVar}{{27}{10}{Standard normal data}{equation.2.27}{}}
\newlabel{eq:normalDqMean}{{28}{10}{Standard normal data}{equation.2.28}{}}
\newlabel{eq:normalVar}{{29}{10}{Standard normal data}{equation.2.29}{}}
\newlabel{eq:normalDistr}{{30}{10}{Standard normal data}{equation.2.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Standard uniform data}{10}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{eq:uniformXmarg}{{31}{10}{Standard uniform data}{equation.2.31}{}}
\newlabel{eq:uniformXMinusZmarg}{{32}{11}{Standard uniform data}{equation.2.32}{}}
\newlabel{eq:uniformXPlusZmarg}{{33}{11}{Standard uniform data}{equation.2.33}{}}
\newlabel{eq:uniformDqPDF}{{34}{11}{Standard uniform data}{equation.2.34}{}}
\newlabel{eq:uniformDqMGF}{{35}{11}{Standard uniform data}{equation.2.35}{}}
\newlabel{eq:1DuniformDqMean}{{36}{11}{Standard uniform data}{equation.2.36}{}}
\newlabel{eq:1DuniformDqVar}{{37}{11}{Standard uniform data}{equation.2.37}{}}
\newlabel{eq:uniformDqMean}{{38}{11}{Standard uniform data}{equation.2.38}{}}
\newlabel{eq:uniformDqVar}{{39}{12}{Standard uniform data}{equation.2.39}{}}
\newlabel{eq:uniformDistr}{{40}{12}{Standard uniform data}{equation.2.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Manhattan ($L_1$)}{12}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Standard normal data}{12}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{eq:normalManMean}{{41}{12}{Standard normal data}{equation.2.41}{}}
\newlabel{eq:normalManVar}{{42}{13}{Standard normal data}{equation.2.42}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Standard uniform data}{13}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{eq:uniformManMean}{{43}{13}{Standard uniform data}{equation.2.43}{}}
\newlabel{eq:uniformManVar}{{44}{13}{Standard uniform data}{equation.2.44}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Distribution of one-dimensional projection of pairwise distance onto an attribute}{13}{subsubsection.2.2.3}\protected@file@percent }
\newlabel{sec:continuous_diff}{{2.2.3}{13}{Distribution of one-dimensional projection of pairwise distance onto an attribute}{subsubsection.2.2.3}{}}
\newlabel{eq:projected_distance_density_normal1}{{45}{14}{Distribution of one-dimensional projection of pairwise distance onto an attribute}{equation.2.45}{}}
\newlabel{eq:1DnormalD1Mean}{{46}{14}{Distribution of one-dimensional projection of pairwise distance onto an attribute}{equation.2.46}{}}
\newlabel{eq:1DnormalD1Var}{{47}{14}{Distribution of one-dimensional projection of pairwise distance onto an attribute}{equation.2.47}{}}
\newlabel{eq:projected_distance_density_uniform1}{{48}{14}{Distribution of one-dimensional projection of pairwise distance onto an attribute}{equation.2.48}{}}
\newlabel{eq:1DuniformD1Mean}{{49}{14}{Distribution of one-dimensional projection of pairwise distance onto an attribute}{equation.2.49}{}}
\newlabel{eq:1DuniformD1Var}{{50}{15}{Distribution of one-dimensional projection of pairwise distance onto an attribute}{equation.2.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Euclidean ($L_2$)}{15}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Standard normal data}{15}{subsubsection.2.3.1}\protected@file@percent }
\newlabel{eq:normalEucMean}{{51}{15}{Standard normal data}{equation.2.51}{}}
\newlabel{eq:normalEucVar}{{52}{15}{Standard normal data}{equation.2.52}{}}
\citation{brazma2000,wang2018}
\citation{urbanowicz17,robnik2003}
\newlabel{eq:normalEucMeanImproved}{{53}{16}{Standard normal data}{equation.2.53}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Standard uniform data}{16}{subsubsection.2.3.2}\protected@file@percent }
\newlabel{eq:uniformEucMean}{{54}{16}{Standard uniform data}{equation.2.54}{}}
\newlabel{eq:uniformEucVar}{{55}{16}{Standard uniform data}{equation.2.55}{}}
\newlabel{eq:uniformEucMeanImproved}{{56}{16}{Standard uniform data}{equation.2.56}{}}
\citation{robnik2003,urbanowicz17}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Distribution of max-min normalized $L_q$ metric}{17}{subsection.2.4}\protected@file@percent }
\newlabel{sec:extremes}{{2.4}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{subsection.2.4}{}}
\newlabel{eq:normDiff}{{57}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.57}{}}
\newlabel{eq:D*}{{58}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.58}{}}
\newlabel{thm:EVT}{{2.2}{17}{Fisher-Tippett-Gnedenko}{theorem.2.2}{}}
\newlabel{eq:exact_max}{{59}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.59}{}}
\newlabel{eq:exact_max_distr_fn}{{60}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.60}{}}
\newlabel{eq:exact_max_dens_fn}{{61}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.61}{}}
\newlabel{eq:exact_min}{{62}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.62}{}}
\newlabel{eq:exact_min_distr_fn}{{63}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.63}{}}
\newlabel{eq:exact_min_dens_fn}{{64}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.64}{}}
\newlabel{eq:mu_max}{{65}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.65}{}}
\newlabel{eq:mu2_max}{{66}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.66}{}}
\newlabel{eq:sig_max}{{67}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.67}{}}
\citation{gumbel1947}
\newlabel{eq:mu_min}{{68}{20}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.68}{}}
\newlabel{eq:mu2_min}{{69}{20}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.69}{}}
\newlabel{eq:sig_min}{{70}{20}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.70}{}}
\newlabel{eq:exp_rng}{{71}{20}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.71}{}}
\newlabel{eq:exp_rng_symm}{{72}{20}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.72}{}}
\newlabel{eq:var_rng}{{73}{21}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.73}{}}
\newlabel{eq:var_rng_symm}{{74}{21}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.74}{}}
\newlabel{eq:max-min_D_mean}{{75}{21}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.75}{}}
\newlabel{eq:max-min_D_var}{{76}{22}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.76}{}}
\newlabel{eq:max-min-DDistr-general}{{77}{22}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.77}{}}
\newlabel{eq:max-min_D_mean_symm}{{78}{22}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.78}{}}
\citation{chatterjee2014}
\newlabel{eq:max-min_D_var_symm}{{79}{23}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.79}{}}
\newlabel{eq:max-min_DDistr}{{80}{23}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.80}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Standard normal data}{23}{subsubsection.2.4.1}\protected@file@percent }
\newlabel{eq:log_expand}{{81}{23}{Standard normal data}{equation.2.81}{}}
\newlabel{eq:mills}{{82}{23}{Standard normal data}{equation.2.82}{}}
\newlabel{eq:approx_log_expand}{{83}{24}{Standard normal data}{equation.2.83}{}}
\newlabel{eq:prob_normal_max}{{84}{24}{Standard normal data}{equation.2.84}{}}
\newlabel{eq:mu_max_normal}{{85}{24}{Standard normal data}{equation.2.85}{}}
\citation{cramer1999}
\citation{cramer1999}
\citation{cramer1999}
\citation{cramer1999}
\citation{gumbel1947}
\newlabel{eq:med_max_normal}{{86}{25}{Standard normal data}{equation.2.86}{}}
\newlabel{eq:var_max_normal}{{87}{25}{Standard normal data}{equation.2.87}{}}
\newlabel{eq:var_max_normal_improved}{{88}{25}{Standard normal data}{equation.2.88}{}}
\newlabel{eq:mu_rng_normal}{{89}{25}{Standard normal data}{equation.2.89}{}}
\newlabel{eq:var_rng_normal}{{90}{25}{Standard normal data}{equation.2.90}{}}
\newlabel{eq:mu_rng_normal_improved}{{91}{26}{Standard normal data}{equation.2.91}{}}
\newlabel{eq:max-min_DDistr_normal}{{92}{26}{Standard normal data}{equation.2.92}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Standard uniform data}{26}{subsubsection.2.4.2}\protected@file@percent }
\newlabel{eq:uniform_max_distr}{{93}{26}{Standard uniform data}{equation.2.93}{}}
\newlabel{eq:uniform_min_distr}{{94}{26}{Standard uniform data}{equation.2.94}{}}
\newlabel{eq:uniform_max_dens}{{95}{26}{Standard uniform data}{equation.2.95}{}}
\newlabel{eq:uniform_min_dens}{{96}{26}{Standard uniform data}{equation.2.96}{}}
\newlabel{eq:mu_max_uniform}{{97}{27}{Standard uniform data}{equation.2.97}{}}
\newlabel{eq:mu_min_uniform}{{98}{27}{Standard uniform data}{equation.2.98}{}}
\newlabel{eq:mu2_rng_uniform}{{99}{27}{Standard uniform data}{equation.2.99}{}}
\newlabel{eq:max-min_DDistr_uniform}{{100}{27}{Standard uniform data}{equation.2.100}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Range-Normalized Manhattan ($q=1$)}{28}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Standard normal data}{28}{subsubsection.2.5.1}\protected@file@percent }
\newlabel{eq:max-min_mean_normal_manhattan}{{101}{28}{Standard normal data}{equation.2.101}{}}
\newlabel{eq:max-min_var_normal_manhattan}{{102}{28}{Standard normal data}{equation.2.102}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Standard uniform data}{28}{subsubsection.2.5.2}\protected@file@percent }
\newlabel{eq:max-min_mean_uniform_manhattan}{{103}{28}{Standard uniform data}{equation.2.103}{}}
\newlabel{eq:max-min_var_uniform_manhattan}{{104}{29}{Standard uniform data}{equation.2.104}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Range-Normalized Euclidean ($q=2$)}{29}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}Standard normal data}{29}{subsubsection.2.6.1}\protected@file@percent }
\newlabel{eq:max-min_mean_normal_euclidean}{{105}{29}{Standard normal data}{equation.2.105}{}}
\newlabel{eq:max-min_var_normal_euclidean}{{106}{29}{Standard normal data}{equation.2.106}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}Standard uniform data}{30}{subsubsection.2.6.2}\protected@file@percent }
\newlabel{eq:max-min_mean_uniform_euclidean}{{107}{30}{Standard uniform data}{equation.2.107}{}}
\newlabel{eq:max-min_var_uniform_euclidean}{{108}{30}{Standard uniform data}{equation.2.108}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces {\bf  Summary of distance distribution derivations for standard normal ($\mathcal  {N}(0,1)$) and standard uniform ($\mathcal  {U}(0,1)$) data.} Asymptotic estimates are given for both standard (Eq.\nobreakspace  {}\ref  {eq:D}) and max-min normalized (Eq.\nobreakspace  {}\ref  {eq:D*}) q-metrics. These estimates are relevant for all $q \in \mathbb  {N}$ and $p \gg 1$ for which the normality assumption of distances holds.\relax }}{30}{figure.caption.4}\protected@file@percent }
\newlabel{tab:dist_distr_general1}{{2}{30}{{\bf Summary of distance distribution derivations for standard normal ($\mathcal {N}(0,1)$) and standard uniform ($\mathcal {U}(0,1)$) data.} Asymptotic estimates are given for both standard (Eq.~\ref {eq:D}) and max-min normalized (Eq.~\ref {eq:D*}) q-metrics. These estimates are relevant for all $q \in \mathbb {N}$ and $p \gg 1$ for which the normality assumption of distances holds.\relax }{figure.caption.4}{}}
\citation{li2014}
\citation{arabnejad2018}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces {\bf  Asymptotic estimates of means and variances for the standard $L_1$ and $L_2$ ($q=1$ and $q=2$ in Fig.\nobreakspace  {}\ref  {tab:dist_distr_general1}) distance distributions.} Estimates for both standard normal ($\mathcal  {N}(0,1)$) and standard uniform ($\mathcal  {U}(0,1)$) data are given.\relax }}{31}{figure.caption.5}\protected@file@percent }
\newlabel{tab:dist_distr_standardL1L2}{{3}{31}{{\bf Asymptotic estimates of means and variances for the standard $L_1$ and $L_2$ ($q=1$ and $q=2$ in Fig.~\ref {tab:dist_distr_general1}) distance distributions.} Estimates for both standard normal ($\mathcal {N}(0,1)$) and standard uniform ($\mathcal {U}(0,1)$) data are given.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces {\bf  Asymptotic estimates of means and variances for the max-min normalized $L_1$ and $L_2$ distance distributions commonly used in Relief-based algorithms.} Estimates for both standard normal ($\mathcal  {N}(0,1)$) and standard uniform ($\mathcal  {U}(0,1)$) data are given. The cumulative distribution function of the standard normal distribution is represented by $\Phi $. Furthermore, $\mu ^{(1)}_\text  {max}(m)$ (Eq.\nobreakspace  {}\ref  {eq:med_max_normal}) is the asymptotic median of the sample maximum from $m$ standard normal random samples.\relax }}{31}{figure.caption.6}\protected@file@percent }
\newlabel{tab:dist_distr_normalizedL1L2}{{4}{31}{{\bf Asymptotic estimates of means and variances for the max-min normalized $L_1$ and $L_2$ distance distributions commonly used in Relief-based algorithms.} Estimates for both standard normal ($\mathcal {N}(0,1)$) and standard uniform ($\mathcal {U}(0,1)$) data are given. The cumulative distribution function of the standard normal distribution is represented by $\Phi $. Furthermore, $\mu ^{(1)}_\text {max}(m)$ (Eq.~\ref {eq:med_max_normal}) is the asymptotic median of the sample maximum from $m$ standard normal random samples.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}GWAS distance distributions}{31}{section.3}\protected@file@percent }
\newlabel{sec:gwas_distances}{{3}{31}{GWAS distance distributions}{section.3}{}}
\newlabel{eq:gwas_data}{{109}{31}{GWAS distance distributions}{equation.3.109}{}}
\newlabel{eq:diff_GM}{{110}{31}{GWAS distance distributions}{equation.3.110}{}}
\newlabel{eq:diff_AM}{{111}{31}{GWAS distance distributions}{equation.3.111}{}}
\newlabel{eq:diff_TiTv}{{112}{32}{GWAS distance distributions}{equation.3.112}{}}
\newlabel{eq:D_GM}{{113}{32}{GWAS distance distributions}{equation.3.113}{}}
\newlabel{eq:D_AM}{{114}{32}{GWAS distance distributions}{equation.3.114}{}}
\newlabel{eq:D_TiTv}{{115}{32}{GWAS distance distributions}{equation.3.115}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}GM distance distribution}{32}{subsection.3.1}\protected@file@percent }
\newlabel{eq:mean_diff_GM}{{116}{32}{GM distance distribution}{equation.3.116}{}}
\newlabel{eq:mu_DDistr_GM}{{117}{33}{GM distance distribution}{equation.3.117}{}}
\newlabel{eq:mu2_DDistr_GM}{{118}{33}{GM distance distribution}{equation.3.118}{}}
\newlabel{eq:var_DDistr_GM}{{119}{33}{GM distance distribution}{equation.3.119}{}}
\newlabel{eq:DDistr_GM}{{120}{34}{GM distance distribution}{equation.3.120}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}AM distance distribution}{34}{subsection.3.2}\protected@file@percent }
\newlabel{eq:mean_diff_AM}{{121}{34}{AM distance distribution}{equation.3.121}{}}
\newlabel{eq:mu_DDistr_AM}{{122}{34}{AM distance distribution}{equation.3.122}{}}
\newlabel{eq:mu2_DDistr_AM}{{123}{35}{AM distance distribution}{equation.3.123}{}}
\newlabel{eq:var_DDistr_AM}{{124}{35}{AM distance distribution}{equation.3.124}{}}
\newlabel{eq:DDistr_AM}{{125}{35}{AM distance distribution}{equation.3.125}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}TiTv distance distribution}{36}{subsection.3.3}\protected@file@percent }
\newlabel{sec:TiTv_distances}{{3.3}{36}{TiTv distance distribution}{subsection.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces {\bf  Purines (A and G) and pyrimidines (C and T) are shown.} Transitions occur when a mutation involves purine-to-purine or pyrimidine-to-pyrimidine insertion. Transversions occur when a purine-to-pyrimidine or pyrimidine-to-purine insertion happens, which is a more extreme case. There are visibly more possibilities for transversions to occur than there are transitions, but there are about twice as many transitions in real data.\relax }}{36}{figure.caption.7}\protected@file@percent }
\newlabel{fig:TiTv_diagram}{{5}{36}{{\bf Purines (A and G) and pyrimidines (C and T) are shown.} Transitions occur when a mutation involves purine-to-purine or pyrimidine-to-pyrimidine insertion. Transversions occur when a purine-to-pyrimidine or pyrimidine-to-purine insertion happens, which is a more extreme case. There are visibly more possibilities for transversions to occur than there are transitions, but there are about twice as many transitions in real data.\relax }{figure.caption.7}{}}
\newlabel{eq:TiTv_constraints1}{{126}{36}{TiTv distance distribution}{equation.3.126}{}}
\newlabel{eq:TiTv_constraints2}{{127}{36}{TiTv distance distribution}{equation.3.127}{}}
\newlabel{eq:prob_Tv}{{128}{36}{TiTv distance distribution}{equation.3.128}{}}
\newlabel{eq:prob_Ti}{{129}{36}{TiTv distance distribution}{equation.3.129}{}}
\newlabel{eq:gamma0}{{130}{37}{TiTv distance distribution}{equation.3.130}{}}
\newlabel{eq:gamma2}{{131}{37}{TiTv distance distribution}{equation.3.131}{}}
\newlabel{eq:yvec}{{132}{37}{TiTv distance distribution}{equation.3.132}{}}
\newlabel{eq:prob_TiTv_0}{{133}{37}{TiTv distance distribution}{equation.3.133}{}}
\newlabel{eq:prob_TiTv_0.25}{{134}{37}{TiTv distance distribution}{equation.3.134}{}}
\newlabel{eq:prob_TiTv_0.5}{{135}{38}{TiTv distance distribution}{equation.3.135}{}}
\newlabel{eq:prob_TiTv_0.75}{{136}{38}{TiTv distance distribution}{equation.3.136}{}}
\newlabel{eq:prob_TiTv_1}{{137}{38}{TiTv distance distribution}{equation.3.137}{}}
\newlabel{eq:mu_DDistr_TiTv}{{138}{38}{TiTv distance distribution}{equation.3.138}{}}
\newlabel{eq:mu2_DDistr_TiTv}{{139}{39}{TiTv distance distribution}{equation.3.139}{}}
\newlabel{eq:var_DDistr_TiTv}{{140}{39}{TiTv distance distribution}{equation.3.140}{}}
\newlabel{eq:DDistr_TiTv}{{141}{40}{TiTv distance distribution}{equation.3.141}{}}
\newlabel{eq:avg_maf}{{142}{40}{TiTv distance distribution}{equation.3.142}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces {\bf  Predicted average TiTv distance as a function of average minor allele frequency $\mathaccentV {bar}016{f}_a$ (see Eq.\nobreakspace  {}\ref  {eq:avg_maf}).} Success probabilities $f_a$ are drawn from a sliding window interval from 0.01 to 0.9 in increments of about 0.009 and $m=p=100$. For $\eta =0.1$, where $\eta $ is the Ti/Tv ratio given by Eq.\nobreakspace  {}\ref  {eq:TiTv_constraints1}, Tv is ten times more likely than Ti and results in larger distance. Increasing to $\eta =1$, Tv and Ti are equally likely and the distance is lower. In line with real data for $\eta =2$, Tv is half as likely as Ti so the distances are relatively small.\relax }}{40}{figure.caption.8}\protected@file@percent }
\newlabel{fig:TiTv-vs-maf}{{6}{40}{{\bf Predicted average TiTv distance as a function of average minor allele frequency $\bar {f}_a$ (see Eq.~\ref {eq:avg_maf}).} Success probabilities $f_a$ are drawn from a sliding window interval from 0.01 to 0.9 in increments of about 0.009 and $m=p=100$. For $\eta =0.1$, where $\eta $ is the Ti/Tv ratio given by Eq.~\ref {eq:TiTv_constraints1}, Tv is ten times more likely than Ti and results in larger distance. Increasing to $\eta =1$, Tv and Ti are equally likely and the distance is lower. In line with real data for $\eta =2$, Tv is half as likely as Ti so the distances are relatively small.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces {\bf  Density curves and moments of TiTv distance as a function of average MAF $\mathaccentV {bar}016{f}_a$, given by Eq.\nobreakspace  {}\ref  {eq:avg_maf}, and Ti/Tv ratio $\eta $, given by Eq.\nobreakspace  {}\ref  {eq:TiTv_constraints2}.} We fix $m=p=100$ for all simulated TiTv distances. (\textbf  {A}) For fixed $\mathaccentV {bar}016{f}_a=0.055$, TiTv distance density is plotted as a function of increasing $\eta $. TiTv distance decreases as $\eta $ increases. For $\eta =\text  {Ti/Tv}=0.5$, there are twice as many transversions as there are transitions. On the other hand, $\eta =\text  {Ti/Tv}=2$ indicates that there are half as many transversions as transitions. Since transversions encode a larger magnitude distance than transitions, this behavior is expected. (\textbf  {B}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing Ti/Tv ratio $\eta $. Distance decreases as Ti/Tv increases. Theoretical and simulated moments are approximately the same. (\textbf  {C}) For fixed $\eta =2$, TiTv distance density is plotted as a function of increasing $\mathaccentV {bar}016{f}_a$. TiTv distance increases as $\mathaccentV {bar}016{f}_a$ approaches maximum of 0.5, which means that there is about the same frequency of minor alleles as major alleles. (\textbf  {D}) Simulated and predicted mean $\pm $ SD as a function of increasing average MAF $\mathaccentV {bar}016{f}_a$. Distance increases as the number of minor alleles increases. Theoretical and simulated moments are approximately the same.\relax }}{41}{figure.caption.9}\protected@file@percent }
\newlabel{fig:TiTv_ridge}{{7}{41}{{\bf Density curves and moments of TiTv distance as a function of average MAF $\bar {f}_a$, given by Eq.~\ref {eq:avg_maf}, and Ti/Tv ratio $\eta $, given by Eq.~\ref {eq:TiTv_constraints2}.} We fix $m=p=100$ for all simulated TiTv distances. (\textbf {A}) For fixed $\bar {f}_a=0.055$, TiTv distance density is plotted as a function of increasing $\eta $. TiTv distance decreases as $\eta $ increases. For $\eta =\text {Ti/Tv}=0.5$, there are twice as many transversions as there are transitions. On the other hand, $\eta =\text {Ti/Tv}=2$ indicates that there are half as many transversions as transitions. Since transversions encode a larger magnitude distance than transitions, this behavior is expected. (\textbf {B}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing Ti/Tv ratio $\eta $. Distance decreases as Ti/Tv increases. Theoretical and simulated moments are approximately the same. (\textbf {C}) For fixed $\eta =2$, TiTv distance density is plotted as a function of increasing $\bar {f}_a$. TiTv distance increases as $\bar {f}_a$ approaches maximum of 0.5, which means that there is about the same frequency of minor alleles as major alleles. (\textbf {D}) Simulated and predicted mean $\pm $ SD as a function of increasing average MAF $\bar {f}_a$. Distance increases as the number of minor alleles increases. Theoretical and simulated moments are approximately the same.\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces {\bf  Asymptotic estimates of means and variances of genotype mismatch (GM) (Eq.\nobreakspace  {}\ref  {eq:D_GM}), allele mismatch (AM) (Eq.\nobreakspace  {}\ref  {eq:D_AM}), and transition-transversion (TiTv) (Eq.\nobreakspace  {}\ref  {eq:D_TiTv}) distance metrics in GWAS data ($p \gg 1$).} GWAS data $X_{ia} \sim \mathcal  {B}(2,f_a)$, where $f_a$ for all $a \in \mathcal  {A}$ are the probabilities of a minor allele occurring at locus $a$. For the TiTv distance metric, we have the additional encoding that uses $\gamma _0=\text  {P}(\text  {PuPu})$, $\gamma _1=\text  {P}(\text  {PuPy})$, and $\gamma _2=\text  {P}(\text  {PyPy})$.\relax }}{41}{figure.caption.10}\protected@file@percent }
\newlabel{tab:dist_distr_gwas}{{8}{41}{{\bf Asymptotic estimates of means and variances of genotype mismatch (GM) (Eq.~\ref {eq:D_GM}), allele mismatch (AM) (Eq.~\ref {eq:D_AM}), and transition-transversion (TiTv) (Eq.~\ref {eq:D_TiTv}) distance metrics in GWAS data ($p \gg 1$).} GWAS data $X_{ia} \sim \mathcal {B}(2,f_a)$, where $f_a$ for all $a \in \mathcal {A}$ are the probabilities of a minor allele occurring at locus $a$. For the TiTv distance metric, we have the additional encoding that uses $\gamma _0=\text {P}(\text {PuPu})$, $\gamma _1=\text {P}(\text {PuPy})$, and $\gamma _2=\text {P}(\text {PyPy})$.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Distribution of one-dimensional projection of GWAS distance onto a SNP}{41}{subsection.3.4}\protected@file@percent }
\newlabel{sec:GWAS_diff}{{3.4}{41}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{subsection.3.4}{}}
\newlabel{eq:probGM0}{{143}{41}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.143}{}}
\newlabel{eq:probGM1}{{144}{41}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.144}{}}
\newlabel{eq:GMdiffPDF}{{145}{42}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.145}{}}
\newlabel{eq:GMdiffMean}{{146}{42}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.146}{}}
\newlabel{eq:GMdiffVar}{{147}{42}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.147}{}}
\newlabel{eq:probAM0}{{148}{42}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.148}{}}
\newlabel{eq:probAM0.5}{{149}{42}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.149}{}}
\newlabel{eq:probAM1}{{150}{42}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.150}{}}
\newlabel{eq:AMdiffPDF}{{151}{42}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.151}{}}
\newlabel{eq:AMdiffMean}{{152}{43}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.152}{}}
\newlabel{eq:AMdiffVar}{{153}{43}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.153}{}}
\newlabel{eq:TiTvdiffPDF}{{154}{43}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.154}{}}
\newlabel{eq:TiTvdiffMean}{{155}{43}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.155}{}}
\newlabel{eq:TiTvdiffVar}{{156}{43}{Distribution of one-dimensional projection of GWAS distance onto a SNP}{equation.3.156}{}}
\citation{lee2013}
\citation{dickie2017}
\@writefile{toc}{\contentsline {section}{\numberline {4}Time series correlation-based distance distribution}{44}{section.4}\protected@file@percent }
\newlabel{sec:rs-fMRI_distances}{{4}{44}{Time series correlation-based distance distribution}{section.4}{}}
\newlabel{eq:diff_rs-fMRI}{{157}{44}{Time series correlation-based distance distribution}{equation.4.157}{}}
\newlabel{eq:D_rs-fMRI}{{158}{44}{Time series correlation-based distance distribution}{equation.4.158}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces {\bf  Organization based on brain regions of interest (ROIs) of resting-state fMRI correlation dataset consisting of transformed correlation matrices for $m$ subjects.} Each column corresponds to an instance (or subject) $I_j$ and each subset of rows corresponds to the correlations for an ROI attribute ($p$ sets). The notation $\mathaccentV {hat}05E{A}^{(j)}_{ak}$ represents the r-to-z transformed correlation between attributes (ROIs) $a$ and $k \not =a$ for instance $j$.\relax }}{44}{figure.caption.11}\protected@file@percent }
\newlabel{fig:rs-fMRI_matrix}{{9}{44}{{\bf Organization based on brain regions of interest (ROIs) of resting-state fMRI correlation dataset consisting of transformed correlation matrices for $m$ subjects.} Each column corresponds to an instance (or subject) $I_j$ and each subset of rows corresponds to the correlations for an ROI attribute ($p$ sets). The notation $\hat {A}^{(j)}_{ak}$ represents the r-to-z transformed correlation between attributes (ROIs) $a$ and $k \neq a$ for instance $j$.\relax }{figure.caption.11}{}}
\newlabel{eq:mu_DDistr_rs-fMRI}{{159}{45}{Time series correlation-based distance distribution}{equation.4.159}{}}
\newlabel{eq:var_DDistr_rs-fMRI_standard}{{160}{45}{Time series correlation-based distance distribution}{equation.4.160}{}}
\newlabel{eq:var_DDistr_rs-fMRI}{{161}{46}{Time series correlation-based distance distribution}{equation.4.161}{}}
\newlabel{eq:estimate_cov}{{162}{47}{Time series correlation-based distance distribution}{equation.4.162}{}}
\newlabel{eq:estimate_cov_form}{{163}{47}{Time series correlation-based distance distribution}{equation.4.163}{}}
\newlabel{eq:var_DDistr_rs-fMRI2}{{164}{47}{Time series correlation-based distance distribution}{equation.4.164}{}}
\newlabel{eq:DDistr_rs-fMRI}{{165}{47}{Time series correlation-based distance distribution}{equation.4.165}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Max-min normalized time series correlation-based distance distribution}{47}{subsection.4.1}\protected@file@percent }
\newlabel{eq:max-min_diff_rs-fMRI}{{166}{47}{Max-min normalized time series correlation-based distance distribution}{equation.4.166}{}}
\newlabel{eq:mean_max_rs-fMRI}{{167}{47}{Max-min normalized time series correlation-based distance distribution}{equation.4.167}{}}
\newlabel{eq:var_max_rs-fMRI}{{168}{48}{Max-min normalized time series correlation-based distance distribution}{equation.4.168}{}}
\newlabel{eq:max-min_DDistr_normal_rs-fMRI}{{169}{48}{Max-min normalized time series correlation-based distance distribution}{equation.4.169}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}One-dimensional projection of rs-fMRI distance onto a single ROI}{48}{subsection.4.2}\protected@file@percent }
\newlabel{sec:rs-fMRI_diff}{{4.2}{48}{One-dimensional projection of rs-fMRI distance onto a single ROI}{subsection.4.2}{}}
\newlabel{eq:rs-fMRI_diffMean}{{170}{48}{One-dimensional projection of rs-fMRI distance onto a single ROI}{equation.4.170}{}}
\newlabel{eq:rs-fMRI_diffVar1}{{171}{49}{One-dimensional projection of rs-fMRI distance onto a single ROI}{equation.4.171}{}}
\newlabel{eq:rs-fMRI_diffVar2}{{172}{49}{One-dimensional projection of rs-fMRI distance onto a single ROI}{equation.4.172}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Normalized Manhattan ($q=1$) for rs-fMRI}{49}{subsection.4.3}\protected@file@percent }
\newlabel{eq:mu_max-min_rs-fMRI}{{174}{49}{Normalized Manhattan \texorpdfstring {($q=1$)}{} for rs-fMRI}{equation.4.174}{}}
\newlabel{eq:var_max-min_rs-fMRI}{{175}{50}{Normalized Manhattan \texorpdfstring {($q=1$)}{} for rs-fMRI}{equation.4.175}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces {\bf  Aymptotic means and variances for the new standard (Eq.\nobreakspace  {}\ref  {eq:D_rs-fMRI}) and max-min normalized (Eq.\nobreakspace  {}\ref  {eq:max-min_diff_rs-fMRI}) rs-fMRI distance metrics.}\relax }}{50}{figure.caption.12}\protected@file@percent }
\newlabel{tab:dist_distr_rs-fMRI}{{10}{50}{{\bf Aymptotic means and variances for the new standard (Eq.~\ref {eq:D_rs-fMRI}) and max-min normalized (Eq.~\ref {eq:max-min_diff_rs-fMRI}) rs-fMRI distance metrics.}\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Comparison of theoretical and sample moments}{50}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces {\bf  Comparison of theoretical and sample moments of Manhattan (Eq.\nobreakspace  {}\ref  {eq:D}) distances in standard normal data. (\textbf  {A}) Scatter plot of theoretical vs simulated mean Manhattan distance (Eq.\nobreakspace  {}\ref  {eq:normalManMean}).} Each point represents a different number of attributes $p$. For each value of $p$ we fixed $m=100$ and generated 20 distance matrices from standard normal data and computed the average simulated pairwise distance from the 20 iterations. The corresponding theoretical mean was then computed for each value of $p$ for comparison. The dashed line represents the identity (or $y=x$) line for reference. (\textbf  {B}) Scatter plot of theoretical vs simulated standard deviation of Manhattan (Eq.\nobreakspace  {}\ref  {eq:D}) distance (Eq.\nobreakspace  {}\ref  {eq:normalManVar}). These standard deviations come from the same random distance matrices for which mean distance was computed for \textbf  {A}. Both theoretical mean and standard deviation approximate the simulated moments quite well.\relax }}{50}{figure.caption.13}\protected@file@percent }
\newlabel{fig:compare_theoretical_sample_moments}{{11}{50}{{\bf Comparison of theoretical and sample moments of Manhattan (Eq.~\ref {eq:D}) distances in standard normal data. (\textbf {A}) Scatter plot of theoretical vs simulated mean Manhattan distance (Eq.~\ref {eq:normalManMean}).} Each point represents a different number of attributes $p$. For each value of $p$ we fixed $m=100$ and generated 20 distance matrices from standard normal data and computed the average simulated pairwise distance from the 20 iterations. The corresponding theoretical mean was then computed for each value of $p$ for comparison. The dashed line represents the identity (or $y=x$) line for reference. (\textbf {B}) Scatter plot of theoretical vs simulated standard deviation of Manhattan (Eq.~\ref {eq:D}) distance (Eq.~\ref {eq:normalManVar}). These standard deviations come from the same random distance matrices for which mean distance was computed for \textbf {A}. Both theoretical mean and standard deviation approximate the simulated moments quite well.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Effects of correlation on distances}{51}{section.6}\protected@file@percent }
\newlabel{sec:correlation}{{6}{51}{Effects of correlation on distances}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Continuous data}{51}{subsection.6.1}\protected@file@percent }
\newlabel{eq:abs_corr}{{176}{51}{Continuous data}{equation.6.176}{}}
\newlabel{eq:cholesky}{{177}{51}{Continuous data}{equation.6.177}{}}
\citation{stir}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}GWAS data}{52}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Time-series derived correlation-based datasets}{52}{subsection.6.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces {\bf  Distance densities from uncorrelated vs correlated bioinformatics data.} (\textbf  {A}) Euclidean distance densities for random normal data with and without correlation. Correlated data was created by multiplying random normal data by upper-triangular Cholesky factor from randomly generated correlation matrix. We created correlated data for average absolute pairwise correlation (Eq.\nobreakspace  {}\ref  {eq:abs_corr}) $\mathaccentV {bar}016{r}_\text  {abs} = 0.105, 0.263, 0.458, \text  { and } 0.612$. (\textbf  {B}) TiTv distance densities for random binomial data with and without correlation. Correlated data was created by first generating correlated standard normal data using the Cholesky method from (A). Then we applied the standard normal CDF to create correlated uniformly distributed data, which was then transformed by the inverse binomial CDF with $n=2$ trials and success probabilites $f_a \text  { for all } a \in \mathcal  {A}$. (\textbf  {C}) Time series correlation-based distance densities for random rs-fMRI data (Fig.\nobreakspace  {}\ref  {fig:rs-fMRI_matrix}) with and without additional pairwise feature correlation. Correlation was added to the transformed rs-fMRI data matrix (Fig.\nobreakspace  {}\ref  {fig:rs-fMRI_matrix}) using the Cholesky algorithm from (A).\relax }}{52}{figure.caption.14}\protected@file@percent }
\newlabel{fig:null_vs_correlated_ridge}{{12}{52}{{\bf Distance densities from uncorrelated vs correlated bioinformatics data.} (\textbf {A}) Euclidean distance densities for random normal data with and without correlation. Correlated data was created by multiplying random normal data by upper-triangular Cholesky factor from randomly generated correlation matrix. We created correlated data for average absolute pairwise correlation (Eq.~\ref {eq:abs_corr}) $\bar {r}_\text {abs} = 0.105, 0.263, 0.458, \text { and } 0.612$. (\textbf {B}) TiTv distance densities for random binomial data with and without correlation. Correlated data was created by first generating correlated standard normal data using the Cholesky method from (A). Then we applied the standard normal CDF to create correlated uniformly distributed data, which was then transformed by the inverse binomial CDF with $n=2$ trials and success probabilites $f_a \text { for all } a \in \mathcal {A}$. (\textbf {C}) Time series correlation-based distance densities for random rs-fMRI data (Fig.~\ref {fig:rs-fMRI_matrix}) with and without additional pairwise feature correlation. Correlation was added to the transformed rs-fMRI data matrix (Fig.~\ref {fig:rs-fMRI_matrix}) using the Cholesky algorithm from (A).\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Improving feature selection with distance distribution informed k}{52}{section.7}\protected@file@percent }
\citation{urbanowicz17}
\citation{stir}
\citation{npdr2}
\citation{cncv}
\citation{lareau15}
\newlabel{eq:msurf_rad}{{178}{53}{Time-series derived correlation-based datasets}{equation.7.178}{}}
\newlabel{eq:k_alpha}{{179}{53}{Time-series derived correlation-based datasets}{equation.7.179}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Data simulation}{53}{subsection.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces \leavevmode {\color  {red}Performance comparison between rule-of-thumb $k=10$ and distance distribution informed $k$. Attribute precision and recall are significantly improved using informed $k$ rather than naive rule-of-thumb $k=10$, whereas no significant difference exists for either training or validation classification accuracy between the two values of $k$.}\relax }}{54}{figure.caption.15}\protected@file@percent }
\newlabel{fig:sim_study}{{13}{54}{\textcolor {red}{Performance comparison between rule-of-thumb $k=10$ and distance distribution informed $k$. Attribute precision and recall are significantly improved using informed $k$ rather than naive rule-of-thumb $k=10$, whereas no significant difference exists for either training or validation classification accuracy between the two values of $k$.}\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Discussion}{54}{section.8}\protected@file@percent }
\newlabel{sec:discussion}{{8}{54}{Discussion}{section.8}{}}
\bibdata{BoD}
\bibcite{urbanowicz17}{1}
\bibcite{urbanowicz17b}{2}
\bibcite{robnik2003}{3}
\bibcite{npdr2}{4}
\bibcite{stir}{5}
\bibcite{mckinney13}{6}
\bibcite{arabnejad2018}{7}
\bibcite{venkataraman2010}{8}
\bibcite{hay2017}{9}
\bibcite{sundermann2014}{10}
\bibcite{vergun2013}{11}
\bibcite{le17}{12}
\bibcite{gotts2012}{13}
\bibcite{liu2019}{14}
\bibcite{t1000}{15}
\bibcite{power2011}{16}
\bibcite{shen2013}{17}
\bibcite{allStats}{18}
\bibcite{freund2004}{19}
\bibcite{brazma2000}{20}
\bibcite{wang2018}{21}
\bibcite{gumbel1947}{22}
\bibcite{chatterjee2014}{23}
\bibcite{cramer1999}{24}
\bibcite{li2014}{25}
\bibcite{lee2013}{26}
\bibcite{dickie2017}{27}
\bibcite{cncv}{28}
\bibcite{lareau15}{29}
\newlabel{LastPage}{{}{58}{}{page.58}{}}
\xdef\lastpage@lastpage{58}
\xdef\lastpage@lastpageHy{58}
