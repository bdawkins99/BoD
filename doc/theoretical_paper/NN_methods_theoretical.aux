\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{urbanowicz17,urbanowicz17b,robnik2003}
\citation{venkataraman2010,hay2017,sundermann2014,vergun2013}
\citation{stir,urbanowicz17,urbanowicz17b}
\citation{arabnejad2018}
\citation{stir}
\citation{stir}
\@writefile{toc}{\contentsline {section}{\numberline {1}Limit distributions for common metrics used in continuous data}{2}{section.1}\protected@file@percent }
\newlabel{sec:notation_and_CLT}{{1}{2}{Limit distributions for common metrics used in continuous data}{section.1}{}}
\newlabel{eq:D}{{1}{2}{Limit distributions for common metrics used in continuous data}{equation.1.1}{}}
\citation{allStats}
\newlabel{eq:diff}{{2}{3}{Limit distributions for common metrics used in continuous data}{equation.1.2}{}}
\newlabel{eq:N}{{3}{3}{Limit distributions for common metrics used in continuous data}{equation.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Asymptotic normality of pairwise distances}{3}{subsection.1.1}\protected@file@percent }
\newlabel{eq:diffDistr}{{4}{3}{Asymptotic normality of pairwise distances}{equation.1.4}{}}
\newlabel{eq:DqAsympt}{{5}{3}{Asymptotic normality of pairwise distances}{equation.1.5}{}}
\newlabel{eq:DqDeltaMethod}{{6}{4}{Asymptotic normality of pairwise distances}{equation.1.6}{}}
\newlabel{eq:DqImprovedExplained}{{7}{4}{Asymptotic normality of pairwise distances}{equation.1.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Convergence to normality of Manhattan and Euclidean distances. For each simulated distance distribution, we fixed the number of instances $m=100$ and vary the number of attributes $p=10,100,10000$. W and P represent the Shapiro-Wilk test statistic and its corresponding P values, respectively. Small P values (e.g., $<0.01$) indicate that the data may not be normally distributed. It is clear that convergence is rapid, and approximate normality can be safely assumed for even $p=10$ (Euclidean).\relax }}{5}{figure.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:central_limit_convergence}{{1}{5}{Convergence to normality of Manhattan and Euclidean distances. For each simulated distance distribution, we fixed the number of instances $m=100$ and vary the number of attributes $p=10,100,10000$. W and P represent the Shapiro-Wilk test statistic and its corresponding P values, respectively. Small P values (e.g., $<0.01$) indicate that the data may not be normally distributed. It is clear that convergence is rapid, and approximate normality can be safely assumed for even $p=10$ (Euclidean).\relax }{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces QQ-plots corresponding to the simulated distances in Fig.\nobreakspace  {}\ref  {fig:central_limit_convergence}. Although there are significant P values for the case of Manhattan for $p=10,100$, it is clear that the assumption of normality is safe due to strong relationship between sample and theoretical quantiles.\relax }}{6}{figure.2}\protected@file@percent }
\newlabel{fig:qq-plots}{{2}{6}{QQ-plots corresponding to the simulated distances in Fig.~\ref {fig:central_limit_convergence}. Although there are significant P values for the case of Manhattan for $p=10,100$, it is clear that the assumption of normality is safe due to strong relationship between sample and theoretical quantiles.\relax }{figure.2}{}}
\citation{freund2004}
\@writefile{toc}{\contentsline {section}{\numberline {2}$L_q$ metric moments for continuous data distributions}{7}{section.2}\protected@file@percent }
\newlabel{sec:moment_derivations}{{2}{7}{\texorpdfstring {$L_q$}{} metric moments for continuous data distributions}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Distribution of $|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{7}{subsection.2.1}\protected@file@percent }
\newlabel{thm:freund}{{2.1}{7}{Distribution of \texorpdfstring {$|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{theorem.2.1}{}}
\newlabel{eq:E(1)}{{12}{8}{Distribution of \texorpdfstring {$|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.12}{}}
\newlabel{eq:E(2)}{{13}{8}{Distribution of \texorpdfstring {$|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.13}{}}
\newlabel{eq:DqCDF}{{14}{8}{Distribution of \texorpdfstring {$|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.14}{}}
\newlabel{eq:DqPDF}{{15}{8}{Distribution of \texorpdfstring {$|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.15}{}}
\newlabel{eq:1DDqMean}{{16}{9}{Distribution of \texorpdfstring {$|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.16}{}}
\newlabel{eq:1DDqVar}{{17}{9}{Distribution of \texorpdfstring {$|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.17}{}}
\newlabel{eq:DqDistr}{{18}{9}{Distribution of \texorpdfstring {$|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.18}{}}
\newlabel{eq:DDistr}{{19}{9}{Distribution of \texorpdfstring {$|d_{ij}(a)|^q = |X_{ia} - X_{ja}|^q$}{}}{equation.2.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Standard normal data}{9}{subsubsection.2.1.1}\protected@file@percent }
\newlabel{eq:normalXmarg}{{20}{9}{Standard normal data}{equation.2.20}{}}
\newlabel{eq:normalXMinusZmarg}{{21}{9}{Standard normal data}{equation.2.21}{}}
\newlabel{eq:normalXPlusZmarg}{{22}{9}{Standard normal data}{equation.2.22}{}}
\newlabel{eq:normalPDF}{{23}{9}{Standard normal data}{equation.2.23}{}}
\newlabel{eq:1DnormalDqMean}{{28}{10}{Standard normal data}{equation.2.28}{}}
\newlabel{eq:1DnormalDqVar}{{29}{10}{Standard normal data}{equation.2.29}{}}
\newlabel{eq:normalDqMean}{{30}{10}{Standard normal data}{equation.2.30}{}}
\newlabel{eq:normalVar}{{31}{10}{Standard normal data}{equation.2.31}{}}
\newlabel{eq:normalDistr}{{32}{10}{Standard normal data}{equation.2.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Standard uniform data}{10}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{eq:uniformXmarg}{{33}{10}{Standard uniform data}{equation.2.33}{}}
\newlabel{eq:uniformXMinusZmarg}{{34}{10}{Standard uniform data}{equation.2.34}{}}
\newlabel{eq:uniformXPlusZmarg}{{35}{11}{Standard uniform data}{equation.2.35}{}}
\newlabel{eq:uniformDqPDF}{{36}{11}{Standard uniform data}{equation.2.36}{}}
\newlabel{eq:uniformDqMGF}{{37}{11}{Standard uniform data}{equation.2.37}{}}
\newlabel{eq:1DuniformDqMean}{{38}{11}{Standard uniform data}{equation.2.38}{}}
\newlabel{eq:1DuniformDqVar}{{39}{11}{Standard uniform data}{equation.2.39}{}}
\newlabel{eq:uniformDqMean}{{40}{11}{Standard uniform data}{equation.2.40}{}}
\newlabel{eq:uniformDqVar}{{41}{12}{Standard uniform data}{equation.2.41}{}}
\newlabel{eq:uniformDistr}{{42}{12}{Standard uniform data}{equation.2.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Manhattan ($L_1$)}{12}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Standard normal data}{12}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{eq:normalManMean}{{43}{12}{Standard normal data}{equation.2.43}{}}
\newlabel{eq:normalManVar}{{44}{13}{Standard normal data}{equation.2.44}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Standard uniform data}{13}{subsubsection.2.2.2}\protected@file@percent }
\newlabel{eq:uniformManMean}{{45}{13}{Standard uniform data}{equation.2.45}{}}
\newlabel{eq:uniformManVar}{{46}{13}{Standard uniform data}{equation.2.46}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Euclidean ($L_2$)}{13}{subsection.2.3}\protected@file@percent }
\citation{brazma2000,wang2018}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Standard normal data}{14}{subsubsection.2.3.1}\protected@file@percent }
\newlabel{eq:normalEucMean}{{47}{14}{Standard normal data}{equation.2.47}{}}
\newlabel{eq:normalEucVar}{{48}{14}{Standard normal data}{equation.2.48}{}}
\newlabel{eq:normalEucMeanImproved}{{49}{14}{Standard normal data}{equation.2.49}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Standard uniform data}{14}{subsubsection.2.3.2}\protected@file@percent }
\citation{urbanowicz17,robnik2003,urbanowiczReliefReview2018}
\citation{robnik2003,urbanowiczReliefReview2018,urbanowicz17}
\newlabel{eq:uniformEucMean}{{50}{15}{Standard uniform data}{equation.2.50}{}}
\newlabel{eq:uniformEucVar}{{51}{15}{Standard uniform data}{equation.2.51}{}}
\newlabel{eq:uniformEucMeanImproved}{{52}{15}{Standard uniform data}{equation.2.52}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Distribution of max-min normalized $L_q$ metric}{15}{subsection.2.4}\protected@file@percent }
\newlabel{sec:extremes}{{2.4}{15}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{subsection.2.4}{}}
\newlabel{eq:normDiff}{{53}{15}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.53}{}}
\newlabel{thm:EVT}{{2.2}{16}{Fisher-Tippett-Gnedenko}{theorem.2.2}{}}
\newlabel{eq:exact_max}{{54}{16}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.54}{}}
\newlabel{eq:exact_max_distr_fn}{{55}{16}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.55}{}}
\newlabel{eq:exact_max_dens_fn}{{56}{16}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.56}{}}
\newlabel{eq:exact_min}{{57}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.57}{}}
\newlabel{eq:exact_min_distr_fn}{{58}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.58}{}}
\newlabel{eq:exact_min_dens_fn}{{59}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.59}{}}
\newlabel{eq:mu_max}{{60}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.60}{}}
\newlabel{eq:mu2_max}{{61}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.61}{}}
\newlabel{eq:sig_max}{{62}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.62}{}}
\newlabel{eq:mu_min}{{63}{17}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.63}{}}
\citation{gumbel1947}
\newlabel{eq:mu2_min}{{64}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.64}{}}
\newlabel{eq:sig_min}{{65}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.65}{}}
\newlabel{eq:exp_rng}{{66}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.66}{}}
\newlabel{eq:exp_rng_symm}{{67}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.67}{}}
\newlabel{eq:var_rng}{{68}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.68}{}}
\newlabel{eq:var_rng_symm}{{69}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.69}{}}
\newlabel{eq:max-min_D_mean}{{70}{18}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.70}{}}
\newlabel{eq:max-min_D_var}{{71}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.71}{}}
\newlabel{eq:max-min-DDistr-general}{{72}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.72}{}}
\newlabel{eq:max-min_D_mean_symm}{{73}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.73}{}}
\newlabel{eq:max-min_D_var_symm}{{74}{19}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.74}{}}
\citation{chatterjee2014}
\newlabel{eq:max-min_DDistr}{{75}{20}{Distribution of max-min normalized \texorpdfstring {$L_q$}{} metric}{equation.2.75}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Standard normal data}{20}{subsubsection.2.4.1}\protected@file@percent }
\newlabel{eq:log_expand}{{76}{20}{Standard normal data}{equation.2.76}{}}
\newlabel{eq:mills}{{77}{20}{Standard normal data}{equation.2.77}{}}
\newlabel{eq:approx_log_expand}{{78}{20}{Standard normal data}{equation.2.78}{}}
\citation{cramer1999}
\citation{gumbel1947}
\newlabel{eq:prob_normal_max}{{79}{21}{Standard normal data}{equation.2.79}{}}
\newlabel{eq:mu_max_normal}{{80}{21}{Standard normal data}{equation.2.80}{}}
\newlabel{eq:med_max_normal}{{81}{21}{Standard normal data}{equation.2.81}{}}
\newlabel{eq:var_max_normal}{{82}{21}{Standard normal data}{equation.2.82}{}}
\newlabel{eq:var_max_normal_improved}{{83}{21}{Standard normal data}{equation.2.83}{}}
\newlabel{eq:mu_rng_normal}{{84}{21}{Standard normal data}{equation.2.84}{}}
\newlabel{eq:var_rng_normal}{{85}{22}{Standard normal data}{equation.2.85}{}}
\newlabel{eq:mu_rng_normal_improved}{{86}{22}{Standard normal data}{equation.2.86}{}}
\newlabel{eq:max-min_DDistr_normal}{{87}{22}{Standard normal data}{equation.2.87}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Standard uniform data}{22}{subsubsection.2.4.2}\protected@file@percent }
\newlabel{eq:uniform_max_distr}{{88}{22}{Standard uniform data}{equation.2.88}{}}
\newlabel{eq:uniform_min_distr}{{89}{22}{Standard uniform data}{equation.2.89}{}}
\newlabel{eq:uniform_max_dens}{{90}{22}{Standard uniform data}{equation.2.90}{}}
\newlabel{eq:uniform_min_dens}{{91}{22}{Standard uniform data}{equation.2.91}{}}
\newlabel{eq:mu_max_uniform}{{92}{23}{Standard uniform data}{equation.2.92}{}}
\newlabel{eq:mu_min_uniform}{{93}{23}{Standard uniform data}{equation.2.93}{}}
\newlabel{eq:mu2_rng_uniform}{{94}{23}{Standard uniform data}{equation.2.94}{}}
\newlabel{eq:max-min_DDistr_uniform}{{95}{23}{Standard uniform data}{equation.2.95}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Normalized Manhattan ($q=1$)}{23}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Standard normal data}{24}{subsubsection.2.5.1}\protected@file@percent }
\newlabel{eq:max-min_manhattan_normal_mean}{{96}{24}{Standard normal data}{equation.2.96}{}}
\newlabel{eq:max-min_manhattan_normal_var}{{97}{24}{Standard normal data}{equation.2.97}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}Standard uniform data}{24}{subsubsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Normalized Euclidean ($q=2$)}{24}{subsection.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.1}Standard normal data}{24}{subsubsection.2.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.6.2}Standard uniform data}{25}{subsubsection.2.6.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of distance distribution derivations for standard normal and standard uniform data. Asymptotic estimates are given for both standard and max-min normalized q-metrics. These estimates are relevant for all $q \in \mathbb  {N}$ and $p \geq 100$.\relax }}{26}{table.caption.4}\protected@file@percent }
\newlabel{tab:dist_distr_general1}{{1}{26}{Summary of distance distribution derivations for standard normal and standard uniform data. Asymptotic estimates are given for both standard and max-min normalized q-metrics. These estimates are relevant for all $q \in \mathbb {N}$ and $p \geq 100$.\relax }{table.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Asymptotic estimates for means and variances for the standard $L_1$ and $L_2$ distance distributions. Estimates for both standard normal and standard uniform data are given.\relax }}{27}{table.caption.5}\protected@file@percent }
\newlabel{tab:dist_distr_standardL1L2}{{2}{27}{Asymptotic estimates for means and variances for the standard $L_1$ and $L_2$ distance distributions. Estimates for both standard normal and standard uniform data are given.\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Asymptotic estimates for means and variances for the max-min normalized $L_1$ and $L_2$ distance distributions. Estimates for both standard normal and standard uniform data are given.\relax }}{28}{table.caption.6}\protected@file@percent }
\newlabel{tab:dist_distr_normalizedL1L2}{{3}{28}{Asymptotic estimates for means and variances for the max-min normalized $L_1$ and $L_2$ distance distributions. Estimates for both standard normal and standard uniform data are given.\relax }{table.caption.6}{}}
\citation{arabnejad2018}
\@writefile{toc}{\contentsline {section}{\numberline {3}GWAS distance distributions}{29}{section.3}\protected@file@percent }
\newlabel{sec:gwas_distances}{{3}{29}{GWAS distance distributions}{section.3}{}}
\newlabel{eq:gwas_data}{{104}{29}{GWAS distance distributions}{equation.3.104}{}}
\newlabel{eq:diff_GM}{{105}{29}{GWAS distance distributions}{equation.3.105}{}}
\newlabel{eq:diff_AM}{{106}{29}{GWAS distance distributions}{equation.3.106}{}}
\newlabel{eq:diff_TiTv}{{107}{29}{GWAS distance distributions}{equation.3.107}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}GM distance distribution}{30}{subsection.3.1}\protected@file@percent }
\newlabel{eq:mean_diff_GM}{{108}{30}{GM distance distribution}{equation.3.108}{}}
\newlabel{eq:mu_DDistr_GM}{{109}{30}{GM distance distribution}{equation.3.109}{}}
\newlabel{eq:mu2_DDistr_GM}{{110}{30}{GM distance distribution}{equation.3.110}{}}
\newlabel{eq:var_DDistr_GM}{{111}{31}{GM distance distribution}{equation.3.111}{}}
\newlabel{eq:DDistr_GM}{{112}{31}{GM distance distribution}{equation.3.112}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}AM distance distribution}{31}{subsection.3.2}\protected@file@percent }
\newlabel{eq:mean_diff_AM}{{113}{31}{AM distance distribution}{equation.3.113}{}}
\newlabel{eq:mu_DDistr_AM}{{114}{31}{AM distance distribution}{equation.3.114}{}}
\newlabel{eq:mu2_DDistr_AM}{{115}{32}{AM distance distribution}{equation.3.115}{}}
\newlabel{eq:var_DDistr_AM}{{116}{32}{AM distance distribution}{equation.3.116}{}}
\newlabel{eq:DDistr_AM}{{117}{32}{AM distance distribution}{equation.3.117}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}TiTv distance distribution}{32}{subsection.3.3}\protected@file@percent }
\newlabel{sec:TiTv_distances}{{3.3}{32}{TiTv distance distribution}{subsection.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Purines (A and G) and pyrimidines (C and T) are shown. Transitions occur when a mutation involves purine-to-purine or pyrimidine-to-pyrimidine insertion. Transversions occur when a purine-to-pyrimidine or pyrimidine-to-purine insertion happens, which is a more extreme case. There are visibly more possibilities for transversions to occur than there are transitions, but there are about twice as many transitions in real data.\relax }}{33}{figure.3}\protected@file@percent }
\newlabel{fig:TiTv_diagram}{{3}{33}{Purines (A and G) and pyrimidines (C and T) are shown. Transitions occur when a mutation involves purine-to-purine or pyrimidine-to-pyrimidine insertion. Transversions occur when a purine-to-pyrimidine or pyrimidine-to-purine insertion happens, which is a more extreme case. There are visibly more possibilities for transversions to occur than there are transitions, but there are about twice as many transitions in real data.\relax }{figure.3}{}}
\newlabel{eq:TiTv_constraints1}{{118}{33}{TiTv distance distribution}{equation.3.118}{}}
\newlabel{eq:TiTv_constraints2}{{119}{33}{TiTv distance distribution}{equation.3.119}{}}
\newlabel{eq:prob_Tv}{{120}{33}{TiTv distance distribution}{equation.3.120}{}}
\newlabel{eq:prob_Ti}{{121}{33}{TiTv distance distribution}{equation.3.121}{}}
\newlabel{eq:gamma0}{{122}{33}{TiTv distance distribution}{equation.3.122}{}}
\newlabel{eq:gamma2}{{123}{33}{TiTv distance distribution}{equation.3.123}{}}
\newlabel{eq:yvec}{{124}{34}{TiTv distance distribution}{equation.3.124}{}}
\newlabel{eq:prob_TiTv_0}{{125}{34}{TiTv distance distribution}{equation.3.125}{}}
\newlabel{eq:prob_TiTv_0.25}{{126}{34}{TiTv distance distribution}{equation.3.126}{}}
\newlabel{eq:prob_TiTv_0.5}{{127}{34}{TiTv distance distribution}{equation.3.127}{}}
\newlabel{eq:prob_TiTv_0.75}{{128}{34}{TiTv distance distribution}{equation.3.128}{}}
\newlabel{eq:prob_TiTv_1}{{129}{35}{TiTv distance distribution}{equation.3.129}{}}
\newlabel{eq:mu_DDistr_TiTv}{{130}{35}{TiTv distance distribution}{equation.3.130}{}}
\newlabel{eq:mu2_DDistr_TiTv}{{131}{35}{TiTv distance distribution}{equation.3.131}{}}
\newlabel{eq:var_DDistr_TiTv}{{132}{36}{TiTv distance distribution}{equation.3.132}{}}
\newlabel{eq:DDistr_TiTv}{{133}{36}{TiTv distance distribution}{equation.3.133}{}}
\newlabel{eq:avg_maf}{{134}{36}{TiTv distance distribution}{equation.3.134}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Predicted average TiTv distance as a function of average minor allele frequency $\mathaccentV {bar}016{f}_a$ (see Eq.\nobreakspace  {}\ref  {eq:avg_maf}). Success probabilities $f_a$ were drawn from a sliding window interval from 0.01 to 0.9 in increments of about 0.009. With $\eta =0.1$, where $\eta $ is the Ti/Tv ratio given by Eq.\nobreakspace  {}\ref  {eq:TiTv_constraints1}, Tv is ten times more likely than Ti so the distance is large. Increasing to $\eta =1$, Tv and Ti are equally likely so the distance is moderate. In line with real data for $\eta =2$, Tv is half as likely as Ti so the distance is relatively small.\relax }}{37}{figure.4}\protected@file@percent }
\newlabel{fig:TiTv-vs-maf}{{4}{37}{Predicted average TiTv distance as a function of average minor allele frequency $\bar {f}_a$ (see Eq.~\ref {eq:avg_maf}). Success probabilities $f_a$ were drawn from a sliding window interval from 0.01 to 0.9 in increments of about 0.009. With $\eta =0.1$, where $\eta $ is the Ti/Tv ratio given by Eq.~\ref {eq:TiTv_constraints1}, Tv is ten times more likely than Ti so the distance is large. Increasing to $\eta =1$, Tv and Ti are equally likely so the distance is moderate. In line with real data for $\eta =2$, Tv is half as likely as Ti so the distance is relatively small.\relax }{figure.4}{}}
\citation{lee2013}
\citation{dickie2017}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Summary of distance distribution derivations for GWAS data.\relax }}{38}{table.caption.7}\protected@file@percent }
\newlabel{tab:dist_distr_gwas}{{4}{38}{Summary of distance distribution derivations for GWAS data.\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Time series correlation-based distance distribution}{38}{section.4}\protected@file@percent }
\newlabel{sec:rs-fMRI_distances}{{4}{38}{Time series correlation-based distance distribution}{section.4}{}}
\newlabel{eq:diff_rs-fMRI}{{135}{38}{Time series correlation-based distance distribution}{equation.4.135}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Resting-state fMRI transformed subject correlation matrices. Each column corresponds to an instance (or subject) $I_j$ and each column corresponds to an ROI (or feature). The notation $\mathaccentV {hat}05E{A}^{(j)}_{ka}$ represents the r-to-z transformed correlation between ROIs $a$ and $k \not =a$ for instance $j$.\relax }}{39}{figure.5}\protected@file@percent }
\newlabel{fig:rs-fMRI_matrix}{{5}{39}{Resting-state fMRI transformed subject correlation matrices. Each column corresponds to an instance (or subject) $I_j$ and each column corresponds to an ROI (or feature). The notation $\hat {A}^{(j)}_{ka}$ represents the r-to-z transformed correlation between ROIs $a$ and $k \neq a$ for instance $j$.\relax }{figure.5}{}}
\newlabel{eq:mu_DDistr_rs-fMRI}{{136}{39}{Time series correlation-based distance distribution}{equation.4.136}{}}
\newlabel{eq:var_DDistr_rs-fMRI}{{137}{40}{Time series correlation-based distance distribution}{equation.4.137}{}}
\newlabel{eq:estimate_cov}{{138}{40}{Time series correlation-based distance distribution}{equation.4.138}{}}
\newlabel{eq:estimate_cov_form}{{139}{40}{Time series correlation-based distance distribution}{equation.4.139}{}}
\newlabel{eq:var_DDistr_rs-fMRI2}{{140}{40}{Time series correlation-based distance distribution}{equation.4.140}{}}
\newlabel{eq:DDistr_rs-fMRI}{{141}{40}{Time series correlation-based distance distribution}{equation.4.141}{}}
\newlabel{eq:max-min_diff_rs-fMRI}{{142}{41}{Time series correlation-based distance distribution}{equation.4.142}{}}
\newlabel{eq:mean_max_rs-fMRI}{{143}{41}{Time series correlation-based distance distribution}{equation.4.143}{}}
\newlabel{eq:var_max_rs-fMRI}{{144}{41}{Time series correlation-based distance distribution}{equation.4.144}{}}
\newlabel{eq:max-min_DDistr_normal_rs-fMRI}{{145}{41}{Time series correlation-based distance distribution}{equation.4.145}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Normalized Manhattan ($q=1$) for rs-fMRI}{41}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Summary of distance distribution derivations for rs-fMRI data.\relax }}{42}{table.caption.8}\protected@file@percent }
\newlabel{tab:dist_distr_rs-fMRI}{{5}{42}{Summary of distance distribution derivations for rs-fMRI data.\relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Effects of correlation on distances}{42}{section.5}\protected@file@percent }
\newlabel{sec:correlation}{{5}{42}{Effects of correlation on distances}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Continuous data}{42}{subsection.5.1}\protected@file@percent }
\newlabel{eq:abs_corr}{{148}{43}{Continuous data}{equation.5.148}{}}
\newlabel{eq:cholesky}{{149}{43}{Continuous data}{equation.5.149}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Density curves of Euclidean distances computed on data with correlated vs uncorrelated features. The average absolute pairwise correlation, given by $r$ (Eq.\nobreakspace  {}\ref  {eq:abs_corr}), is a measure of the deviation from normality in distances. When $r=0.103$, correlated distances closely approximate uncorrelated distances. With $r=0.246$, the increased correlation causes significant positive skewness in distances. In the cases of $r=0.436$ and $r=0.597$, the positive skewness becomes more extreme and correlated distances diverge maximally from the uncorrelated distance distribution. The average correlated and uncorrelated distances are approximately the same for each value of $r$, however, the standard deviation of correlated distances are far larger than that of uncorrelated distances.\relax }}{44}{figure.6}\protected@file@percent }
\newlabel{fig:null-vs-corr-normal}{{6}{44}{Density curves of Euclidean distances computed on data with correlated vs uncorrelated features. The average absolute pairwise correlation, given by $r$ (Eq.~\ref {eq:abs_corr}), is a measure of the deviation from normality in distances. When $r=0.103$, correlated distances closely approximate uncorrelated distances. With $r=0.246$, the increased correlation causes significant positive skewness in distances. In the cases of $r=0.436$ and $r=0.597$, the positive skewness becomes more extreme and correlated distances diverge maximally from the uncorrelated distance distribution. The average correlated and uncorrelated distances are approximately the same for each value of $r$, however, the standard deviation of correlated distances are far larger than that of uncorrelated distances.\relax }{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}GWAS data}{44}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Density curves of TiTv distances computed on data with correlated vs uncorrelated features. The average absolute pairwise correlation, given by $r$ (Eq.\nobreakspace  {}\ref  {eq:abs_corr}), is a measure of the deviation from normality in distances. There is very little difference between correlated vs uncorrelated distances when $r=0.086$. When $r=0.147$, correlated distances begin to show positive skewness. Increasing to $r=0.227$ and $r=0.299$, correlated distances show extreme skewness. Compared to Fig.\nobreakspace  {}\ref  {fig:null-vs-corr-normal}, it appears that correlation more drastically affects distances in discrete GWAS data than $L_q$ distances in continuous data. This could have important implications for the choice of neighborhood parameters in nearest-neighbor distance-based feature selection. As in continuous data, the average correlated and uncorrelated TiTv distances are approximately the same with clear differences in standard deviations.\relax }}{45}{figure.7}\protected@file@percent }
\newlabel{fig:null-vs-corr-titv}{{7}{45}{Density curves of TiTv distances computed on data with correlated vs uncorrelated features. The average absolute pairwise correlation, given by $r$ (Eq.~\ref {eq:abs_corr}), is a measure of the deviation from normality in distances. There is very little difference between correlated vs uncorrelated distances when $r=0.086$. When $r=0.147$, correlated distances begin to show positive skewness. Increasing to $r=0.227$ and $r=0.299$, correlated distances show extreme skewness. Compared to Fig.~\ref {fig:null-vs-corr-normal}, it appears that correlation more drastically affects distances in discrete GWAS data than $L_q$ distances in continuous data. This could have important implications for the choice of neighborhood parameters in nearest-neighbor distance-based feature selection. As in continuous data, the average correlated and uncorrelated TiTv distances are approximately the same with clear differences in standard deviations.\relax }{figure.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Correlation-based data}{45}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Density curves of rs-fMRI distances on data with correlated vs uncorrelated features. The average absolute pairwise correlation, given by $r$ (Eq.\nobreakspace  {}\ref  {eq:abs_corr}), is a measure of the deviation from normality in distances. Even with the relatively small $r=0.09$, there is significant deviation from uncorrelated distances with increased variance and some positive skewness. A small increase to $r=0.118$ causes rather extreme positive skewness to develop in correlated distances. As we increase to $r=0.163$ and $r=0.218$, the differences between correlated and uncorrelated rs-fMRI distances become much more pronounced. It appears that the feature-feature dependencies have the largest impact on time series correlation-based data like rs-fMRI. The data already consists of pairwise correlations between ROIs, which are transformed into a single $m \times p(p-1)$ data set. Correlation is then added on top of these transformed ROI-ROI correlations to give what is shown in this figure. The average distances in uncorrelated and correlated distances are still approximately the same for this data type, with obvious differences in variance.\relax }}{46}{figure.8}\protected@file@percent }
\newlabel{fig:null-vs-corr-rsfMRI}{{8}{46}{Density curves of rs-fMRI distances on data with correlated vs uncorrelated features. The average absolute pairwise correlation, given by $r$ (Eq.~\ref {eq:abs_corr}), is a measure of the deviation from normality in distances. Even with the relatively small $r=0.09$, there is significant deviation from uncorrelated distances with increased variance and some positive skewness. A small increase to $r=0.118$ causes rather extreme positive skewness to develop in correlated distances. As we increase to $r=0.163$ and $r=0.218$, the differences between correlated and uncorrelated rs-fMRI distances become much more pronounced. It appears that the feature-feature dependencies have the largest impact on time series correlation-based data like rs-fMRI. The data already consists of pairwise correlations between ROIs, which are transformed into a single $m \times p(p-1)$ data set. Correlation is then added on top of these transformed ROI-ROI correlations to give what is shown in this figure. The average distances in uncorrelated and correlated distances are still approximately the same for this data type, with obvious differences in variance.\relax }{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Density curves of TiTv distance as a function of average MAF $\mathaccentV {bar}016{f}_a$, given by Eq.\nobreakspace  {}\ref  {eq:avg_maf}, and Ti/Tv ratio $\eta $, given by Eq.\nobreakspace  {}\ref  {eq:TiTv_constraints2}. (\textbf  {A}) For fixed $\eta =2$, TiTv distance density is plotted as a function of increasing $\mathaccentV {bar}016{f}_a = 0.055, 0.150, 0.250, \text  { and } 0.350$. TiTv distance increases as $\mathaccentV {bar}016{f}_a$ approaches a maximum of 0.5, which means that there is about the same frequency of minor alleles as primary alleles at locus $a$. (\textbf  {B}) For fixed $\mathaccentV {bar}016{f}_a=0.055$, TiTv distance density is plotted as a function of increasing $\eta = 0.5, 1, 1.5, \text  { and } 2$. TiTv distance decreases as $\eta $, the Ti/Tv ratio, increases. For $\eta =\text  {Ti/Tv}=0.5$, there are twice as many transversions as there are transitions. On the other hand, $\eta =\text  {Ti/Tv}=2$ indicates that there are half as many transversions as there are transitions. Since transversions encode a larger magnitude distance than transitions in Eq.\nobreakspace  {}\ref  {eq:diff_TiTv}, this behavior is expected.\relax }}{47}{figure.9}\protected@file@percent }
\newlabel{fig:TiTv_hist}{{9}{47}{Density curves of TiTv distance as a function of average MAF $\bar {f}_a$, given by Eq.~\ref {eq:avg_maf}, and Ti/Tv ratio $\eta $, given by Eq.~\ref {eq:TiTv_constraints2}. (\textbf {A}) For fixed $\eta =2$, TiTv distance density is plotted as a function of increasing $\bar {f}_a = 0.055, 0.150, 0.250, \text { and } 0.350$. TiTv distance increases as $\bar {f}_a$ approaches a maximum of 0.5, which means that there is about the same frequency of minor alleles as primary alleles at locus $a$. (\textbf {B}) For fixed $\bar {f}_a=0.055$, TiTv distance density is plotted as a function of increasing $\eta = 0.5, 1, 1.5, \text { and } 2$. TiTv distance decreases as $\eta $, the Ti/Tv ratio, increases. For $\eta =\text {Ti/Tv}=0.5$, there are twice as many transversions as there are transitions. On the other hand, $\eta =\text {Ti/Tv}=2$ indicates that there are half as many transversions as there are transitions. Since transversions encode a larger magnitude distance than transitions in Eq.~\ref {eq:diff_TiTv}, this behavior is expected.\relax }{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces TiTv distance predicted and simulated moments as a function of Ti/Tv ratio $\eta $ and average MAF $\mathaccentV {bar}016{f}_a$ given by Eqs.\nobreakspace  {}\ref  {eq:TiTv_constraints2} and \ref  {eq:avg_maf}, respectively. (\textbf  {A}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing Ti/Tv ratio $\eta $. Distance decreases as Tv becomes more frequent than Ti. Theoretical standard deviation is slightly larger than simulated, but the means are approximately the same. (\textbf  {B}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing average MAF $\mathaccentV {bar}016{f}_a$. Distance increases as the number of minor alleles increases at each locus $a$. Theoretical and simulated moments are approximately the same.\relax }}{47}{figure.10}\protected@file@percent }
\newlabel{fig:TiTv_meanSD}{{10}{47}{TiTv distance predicted and simulated moments as a function of Ti/Tv ratio $\eta $ and average MAF $\bar {f}_a$ given by Eqs.~\ref {eq:TiTv_constraints2} and \ref {eq:avg_maf}, respectively. (\textbf {A}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing Ti/Tv ratio $\eta $. Distance decreases as Tv becomes more frequent than Ti. Theoretical standard deviation is slightly larger than simulated, but the means are approximately the same. (\textbf {B}) Simulated and predicted mean $\pm $ SD are shown as a function of increasing average MAF $\bar {f}_a$. Distance increases as the number of minor alleles increases at each locus $a$. Theoretical and simulated moments are approximately the same.\relax }{figure.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{48}{section.6}\protected@file@percent }
\newlabel{sec:discussion}{{6}{48}{Discussion}{section.6}{}}
\bibstyle{unsrt}
\bibdata{BoD}
\bibcite{urbanowicz17}{1}
\bibcite{urbanowicz17b}{2}
\bibcite{robnik2003}{3}
\bibcite{venkataraman2010}{4}
\bibcite{hay2017}{5}
\bibcite{sundermann2014}{6}
\bibcite{vergun2013}{7}
\bibcite{stir}{8}
\bibcite{arabnejad2018}{9}
\bibcite{allStats}{10}
\bibcite{freund2004}{11}
\bibcite{brazma2000}{12}
\bibcite{wang2018}{13}
\bibcite{urbanowiczReliefReview2018}{14}
\bibcite{gumbel1947}{15}
\bibcite{chatterjee2014}{16}
\bibcite{cramer1999}{17}
\bibcite{lee2013}{18}
\bibcite{dickie2017}{19}
\newlabel{LastPage}{{}{50}{}{page.50}{}}
\xdef\lastpage@lastpage{50}
\xdef\lastpage@lastpageHy{50}
